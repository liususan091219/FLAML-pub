{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43f7-wG-Tjg_"
      },
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved. \n",
        "\n",
        "Licensed under the MIT License.\n",
        "\n",
        "# FineTuning NLP Models with FLAML Library\n",
        "\n",
        "\n",
        "## 1. Introduction\n",
        "\n",
        "FLAML is a Python library (https://github.com/microsoft/FLAML) designed to automatically produce accurate machine learning models \n",
        "with low computational cost. It is fast and economical. The simple and lightweight design makes it easy to use and extend, such as adding new learners. FLAML can \n",
        "- serve as an economical AutoML engine,\n",
        "- be used as a fast hyperparameter tuning tool, or \n",
        "- be embedded in self-tuning software that requires low latency & resource in repetitive\n",
        "   tuning tasks.\n",
        "\n",
        "In this notebook, we demonstrate how to use the FLAML library to fine tune an NLP language model with hyperparameter search. We will use [flaml.tune](https://microsoft.github.io/FLAML/docs/Use-Cases/Tune-User-Defined-Function) with the built in GPU in colab for the tuning. However, if you have a machine with more than 1 GPU, you can also use FLAML's [parallel tuning](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML#parallel-tuning) with the ray tune option. \n",
        "\n",
        "FLAML requires `Python>=3.7`. To run this notebook example, please install flaml with the `nlp,notebook` and `blendsearch` option:\n",
        "```bash\n",
        "pip install flaml[nlp,notebook,blendsearch];\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8c3VMy6TjhC",
        "outputId": "95d7f1f4-78a9-4ac9-d5af-3991bbb77287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flaml[blendsearch,nlp,notebook]\n",
            "  Downloading FLAML-1.0.10-py3-none-any.whl (205 kB)\n",
            "\u001b[K     |████████████████████████████████| 205 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from flaml[blendsearch,nlp,notebook]) (1.7.3)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from flaml[blendsearch,nlp,notebook]) (1.3.5)\n",
            "Requirement already satisfied: NumPy>=1.17.0rc1 in /usr/local/lib/python3.7/dist-packages (from flaml[blendsearch,nlp,notebook]) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from flaml[blendsearch,nlp,notebook]) (1.0.2)\n",
            "Requirement already satisfied: xgboost>=0.90 in /usr/local/lib/python3.7/dist-packages (from flaml[blendsearch,nlp,notebook]) (0.90)\n",
            "Collecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 54.8 MB/s \n",
            "\u001b[?25hCollecting optuna==2.8.0\n",
            "  Downloading optuna-2.8.0-py3-none-any.whl (301 kB)\n",
            "\u001b[K     |████████████████████████████████| 301 kB 62.0 MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "\u001b[K     |████████████████████████████████| 365 kB 57.7 MB/s \n",
            "\u001b[?25hCollecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 782 kB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from flaml[blendsearch,nlp,notebook]) (3.7)\n",
            "Collecting transformers[torch]==4.18\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 38.3 MB/s \n",
            "\u001b[?25hCollecting catboost>=0.26\n",
            "  Downloading catboost-1.0.6-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flaml[blendsearch,nlp,notebook]) (3.2.2)\n",
            "Collecting jupyter\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting openml==0.10.2\n",
            "  Downloading openml-0.10.2.tar.gz (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 72.4 MB/s \n",
            "\u001b[?25hCollecting rgf-python\n",
            "  Downloading rgf_python-3.12.0-py3-none-manylinux1_x86_64.whl (757 kB)\n",
            "\u001b[K     |████████████████████████████████| 757 kB 25.1 MB/s \n",
            "\u001b[?25hCollecting liac-arff>=2.4.0\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[blendsearch,nlp,notebook]) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[blendsearch,nlp,notebook]) (2.8.2)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 10.7 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 69.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna==2.8.0->flaml[blendsearch,nlp,notebook]) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.8.0->flaml[blendsearch,nlp,notebook]) (21.3)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.8.0->flaml[blendsearch,nlp,notebook]) (1.4.40)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 63.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 37.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 54.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.18->flaml[blendsearch,nlp,notebook]) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.18->flaml[blendsearch,nlp,notebook]) (4.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.18->flaml[blendsearch,nlp,notebook]) (3.8.0)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.18->flaml[blendsearch,nlp,notebook]) (1.12.1+cu113)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost>=0.26->flaml[blendsearch,nlp,notebook]) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost>=0.26->flaml[blendsearch,nlp,notebook]) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost>=0.26->flaml[blendsearch,nlp,notebook]) (5.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[torch]==4.18->flaml[blendsearch,nlp,notebook]) (4.1.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->flaml[blendsearch,nlp,notebook]) (0.37.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna==2.8.0->flaml[blendsearch,nlp,notebook]) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->flaml[blendsearch,nlp,notebook]) (2022.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml[blendsearch,nlp,notebook]) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml[blendsearch,nlp,notebook]) (1.1.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna==2.8.0->flaml[blendsearch,nlp,notebook]) (1.1.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.1-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna==2.8.0->flaml[blendsearch,nlp,notebook]) (5.9.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 75.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.8.0->flaml[blendsearch,nlp,notebook]) (3.3.0)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.10.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 71.0 MB/s \n",
            "\u001b[?25hCollecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.8.0->flaml[blendsearch,nlp,notebook]) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.8.0->flaml[blendsearch,nlp,notebook]) (22.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[torch]==4.18->flaml[blendsearch,nlp,notebook]) (3.8.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets->flaml[blendsearch,nlp,notebook]) (3.8.1)\n",
            "Collecting fsspec[http]>=2021.11.1\n",
            "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 68.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets->flaml[blendsearch,nlp,notebook]) (0.3.5.1)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->flaml[blendsearch,nlp,notebook]) (6.0.1)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 73.7 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 67.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[blendsearch,nlp,notebook]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[blendsearch,nlp,notebook]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[blendsearch,nlp,notebook]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[blendsearch,nlp,notebook]) (2022.6.15)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 73.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook]) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook]) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook]) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook]) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook]) (1.8.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook]) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook]) (2.1.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[blendsearch,nlp,notebook]) (5.3.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[blendsearch,nlp,notebook]) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[blendsearch,nlp,notebook]) (5.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[blendsearch,nlp,notebook]) (7.7.1)\n",
            "Collecting qtconsole\n",
            "  Downloading qtconsole-5.3.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 60.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[blendsearch,nlp,notebook]) (5.3.4)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook]) (6.1.12)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook]) (7.9.0)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook]) (5.1.1)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook]) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[blendsearch,nlp,notebook]) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[blendsearch,nlp,notebook]) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[blendsearch,nlp,notebook]) (0.7.5)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[blendsearch,nlp,notebook]) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[blendsearch,nlp,notebook]) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[blendsearch,nlp,notebook]) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[blendsearch,nlp,notebook]) (57.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter->flaml[blendsearch,nlp,notebook]) (0.8.3)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[blendsearch,nlp,notebook]) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[blendsearch,nlp,notebook]) (3.6.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[blendsearch,nlp,notebook]) (1.1.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[blendsearch,nlp,notebook]) (4.11.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[blendsearch,nlp,notebook]) (5.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[blendsearch,nlp,notebook]) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[blendsearch,nlp,notebook]) (0.13.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[blendsearch,nlp,notebook]) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->flaml[blendsearch,nlp,notebook]) (23.2.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->flaml[blendsearch,nlp,notebook]) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->flaml[blendsearch,nlp,notebook]) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flaml[blendsearch,nlp,notebook]) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flaml[blendsearch,nlp,notebook]) (1.4.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook]) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook]) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook]) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook]) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook]) (5.0.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook]) (0.4)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->flaml[blendsearch,nlp,notebook]) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->flaml[blendsearch,nlp,notebook]) (2.16.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->flaml[blendsearch,nlp,notebook]) (0.18.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->flaml[blendsearch,nlp,notebook]) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->flaml[blendsearch,nlp,notebook]) (7.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost>=0.26->flaml[blendsearch,nlp,notebook]) (8.0.1)\n",
            "Collecting qtpy>=2.0.1\n",
            "  Downloading QtPy-2.2.0-py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 625 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score->flaml[blendsearch,nlp,notebook]) (1.2.0)\n",
            "Building wheels for collected packages: openml, liac-arff, pyperclip, rouge-score, sacremoses, seqeval\n",
            "  Building wheel for openml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openml: filename=openml-0.10.2-py3-none-any.whl size=190318 sha256=70e2337e05ee6c2ff1c2ed85cad98da230eaa06271dd7ae34f6154d14d633367\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/9e/f3/6a5ebf16527d7fe22d9bc1652bc9beb5dc9fcfdeb75e805400\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11732 sha256=54259e28a8d4071610df7acfd17a92f75c7a6b04fd36b067399b93170aa4debd\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/0f/15/332ca86cbebf25ddf98518caaf887945fbe1712b97a0f2493b\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=67aa3047dd52495913f12d845f752b919e9f733af5081c7e70bb8a0a68659cfa\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=e798fbb58b7b0dd886a03d07d882c0a1b0196b28b6fc1f5152535cf5486adf8b\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ac/6b/38096e3c5bf1dc87911e3585875e21a3ac610348e740409c76\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=66add84b125ace811238ab8b1b8b00c250b095fc8351717bca7401fb3b4cca20\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=689fed065cca34392ef02e69bbe7fc74cf5e0591bdb9fbb9448f3f29ced34e8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built openml liac-arff pyperclip rouge-score sacremoses seqeval\n",
            "Installing collected packages: jedi, urllib3, pyyaml, pyperclip, pbr, tokenizers, stevedore, sacremoses, qtpy, Mako, huggingface-hub, fsspec, cmd2, autopage, xxhash, xmltodict, transformers, responses, qtconsole, multiprocess, lightgbm, liac-arff, colorlog, cmaes, cliff, alembic, seqeval, rouge-score, rgf-python, optuna, openml, jupyter, flaml, datasets, catboost\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed Mako-1.2.1 alembic-1.8.1 autopage-0.5.1 catboost-1.0.6 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.2 colorlog-6.6.0 datasets-2.4.0 flaml-1.0.10 fsspec-2022.7.1 huggingface-hub-0.8.1 jedi-0.18.1 jupyter-1.0.0 liac-arff-2.5.0 lightgbm-3.3.2 multiprocess-0.70.13 openml-0.10.2 optuna-2.8.0 pbr-5.10.0 pyperclip-1.8.2 pyyaml-6.0 qtconsole-5.3.1 qtpy-2.2.0 responses-0.18.0 rgf-python-3.12.0 rouge-score-0.1.2 sacremoses-0.0.53 seqeval-1.2.2 stevedore-3.5.0 tokenizers-0.12.1 transformers-4.18.0 urllib3-1.25.11 xmltodict-0.13.0 xxhash-3.0.0\n"
          ]
        }
      ],
      "source": [
        "%pip install flaml[nlp,notebook,blendsearch]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efPlAWTdTjhD"
      },
      "source": [
        "Let's run some examples. To use CoLab's built in GPU, you need to select Runtime -> Change runtime type and select GPU. Then you can print the device information using:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print([torch.cuda.device(i) for i in range(torch.cuda.device_count())])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kx9QbI7uaU8",
        "outputId": "7230bc32-18da-475b-f2c2-fb0b5d348d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<torch.cuda.device object at 0x7fdd3bf7e750>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: throughout this notebook, you may see a few ModuleNotFoundErrors. As long as the cell successfully executes, you can ignore that error."
      ],
      "metadata": {
        "id": "-yEuLXoHua-f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBr83DYlTjhD"
      },
      "source": [
        "## 2. Sentiment Classification Example\n",
        "### Load data and preprocess\n",
        "\n",
        "The Stanford Sentiment treebank (SST-2) dataset is a dataset for sentiment classification. First, let's load this dataset into pandas dataframes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGP2eqTBTjhD",
        "outputId": "f0c24b5a-ebc5-4bbb-eeec-24a332862d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "WARNING:datasets.builder:Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "WARNING:datasets.builder:Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_dataset = load_dataset(\"glue\", \"sst2\", split=\"train\").to_pandas()\n",
        "dev_dataset = load_dataset(\"glue\", \"sst2\", split=\"validation\").to_pandas()\n",
        "test_dataset = load_dataset(\"glue\", \"sst2\", split=\"test\").to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb7SAWVLTjhE"
      },
      "source": [
        "Take a look at the first 5 examples of this dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65mLkoJhTjhE",
        "outputId": "2ec2ba75-caeb-4e6e-e1f8-78ee900f525d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hide new secretions from the parental units</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>contains no wit , only labored gags</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>that loves its characters and communicates som...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>remains utterly satisfied to remain the same t...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  label  idx\n",
              "0       hide new secretions from the parental units       0    0\n",
              "1               contains no wit , only labored gags       0    1\n",
              "2  that loves its characters and communicates som...      1    2\n",
              "3  remains utterly satisfied to remain the same t...      0    3\n",
              "4  on the worst revenge-of-the-nerds clichés the ...      0    4"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENcUQbOgTjhE"
      },
      "source": [
        "Separate the data into X and y:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GA0VH9URTjhF"
      },
      "outputs": [],
      "source": [
        "custom_sent_keys = [\"sentence\"]          # specify the column names of the input sentences\n",
        "label_key = \"label\"                                    # specify the column name of the label\n",
        "\n",
        "X_train, y_train = train_dataset[custom_sent_keys], train_dataset[label_key]\n",
        "X_val, y_val = dev_dataset[custom_sent_keys], dev_dataset[label_key]\n",
        "X_test = test_dataset[custom_sent_keys]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpRqB153TjhF"
      },
      "source": [
        "### Run FLAML"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can run AutoML with FLAML:"
      ],
      "metadata": {
        "id": "2kXabqxZuzQl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asYbkzrXTjhF"
      },
      "outputs": [],
      "source": [
        "\n",
        "from flaml import AutoML\n",
        "automl = AutoML()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's will run FLAML for 30 mins. Here we will Electra's [small model](https://huggingface.co/google/electra-small-discriminator) for the tuning. We set gpu_per_trial to 1, and n_concurrent_trials to 1 (the number of trials running at the same time). Make sure gpu_per_trial * n_concurrent_trials does not exceed the GPU number you have. While running you can observe the resource usage (including the GPU) on the right. "
      ],
      "metadata": {
        "id": "2XZmrBRru_A0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEvR2bZiTjhG"
      },
      "outputs": [],
      "source": [
        "TIME_BUDGET=1800\n",
        "automl_settings = {\n",
        "    \"time_budget\": TIME_BUDGET,                  # setting the time budget\n",
        "    \"task\": \"seq-classification\",       # setting the task as seq-classification\n",
        "    \"fit_kwargs_by_estimator\": {\n",
        "        \"transformer\": {\n",
        "            \"output_dir\": \"data/output/\",   # setting the output directory\n",
        "            \"model_path\": \"google/electra-small-discriminator\",  # if model_path is not set, the default model is facebook/muppet-roberta-base: https://huggingface.co/facebook/muppet-roberta-base\n",
        "        }\n",
        "    },\n",
        "    \"gpu_per_trial\": 1,                 # using 1 GPU for each trial\n",
        "    \"log_file_name\": \"seqclass.log\",    # set the file to save the log for HPO\n",
        "    \"log_type\": \"all\",                  # the log type for trials: \"all\" if logging all the trials, \"better\" if only keeping the better trials\n",
        "    \"use_ray\": False,                   # If parallel tuning, set \"use_ray\" to {\"local_dir\": \"data/output/\"}\n",
        "    \"n_concurrent_trials\": 1,           # How many trials to run at the same time, n_concurrent_trials * gpu_per_trial must not exceed the total number of GPUs\n",
        "    \"keep_search_state\": True,          # keeping the search state\n",
        "    \"fp16\": False                       # whether to use fp16, this option is True by default. \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXjF65hOTjhG",
        "outputId": "d88914eb-ccea-47ce-be79-d03cce802744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n",
            "[flaml.automl: 08-17 15:31:14] {2540} INFO - task = seq-classification\n",
            "INFO:flaml.automl:task = seq-classification\n",
            "[flaml.automl: 08-17 15:31:14] {2542} INFO - Data split method: stratified\n",
            "INFO:flaml.automl:Data split method: stratified\n",
            "[flaml.automl: 08-17 15:31:14] {2545} INFO - Evaluation method: holdout\n",
            "INFO:flaml.automl:Evaluation method: holdout\n",
            "[flaml.automl: 08-17 15:31:14] {2664} INFO - Minimizing error metric: 1-accuracy\n",
            "INFO:flaml.automl:Minimizing error metric: 1-accuracy\n",
            "[flaml.automl: 08-17 15:31:14] {2806} INFO - List of ML learners in AutoML Run: ['transformer']\n",
            "INFO:flaml.automl:List of ML learners in AutoML Run: ['transformer']\n",
            "[flaml.automl: 08-17 15:31:14] {3108} INFO - iteration 0, current learner transformer\n",
            "INFO:flaml.automl:iteration 0, current learner transformer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.5665, 'learning_rate': 4.6751863684771026e-06, 'epoch': 1.6}\n",
            "{'eval_loss': 0.42372697591781616, 'eval_automl_metric': 0.1754587155963303, 'eval_runtime': 17.562, 'eval_samples_per_second': 49.653, 'eval_steps_per_second': 49.653, 'epoch': 2.0}\n",
            "{'eval_loss': 0.4013928174972534, 'eval_automl_metric': 0.16399082568807344, 'eval_runtime': 18.2967, 'eval_samples_per_second': 47.659, 'eval_steps_per_second': 47.659, 'epoch': 3.0}\n",
            "{'train_runtime': 94.3311, 'train_samples_per_second': 318.029, 'train_steps_per_second': 9.954, 'train_loss': 0.48752916557466386, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 872\n",
            "  Batch size = 1\n",
            "Didn't find file data/output/train_2022-08-17_15-31-14/train_a173ec96_6_s=9223372036854775807,e=1e-05,s=-1,s=3,e=32,d=20_2022-08-17_15-31-14/checkpoint-939/added_tokens.json. We won't load it.\n",
            "loading file data/output/train_2022-08-17_15-31-14/train_a173ec96_6_s=9223372036854775807,e=1e-05,s=-1,s=3,e=32,d=20_2022-08-17_15-31-14/checkpoint-939/vocab.txt\n",
            "loading file data/output/train_2022-08-17_15-31-14/train_a173ec96_6_s=9223372036854775807,e=1e-05,s=-1,s=3,e=32,d=20_2022-08-17_15-31-14/checkpoint-939/tokenizer.json\n",
            "loading file None\n",
            "loading file data/output/train_2022-08-17_15-31-14/train_a173ec96_6_s=9223372036854775807,e=1e-05,s=-1,s=3,e=32,d=20_2022-08-17_15-31-14/checkpoint-939/special_tokens_map.json\n",
            "loading file data/output/train_2022-08-17_15-31-14/train_a173ec96_6_s=9223372036854775807,e=1e-05,s=-1,s=3,e=32,d=20_2022-08-17_15-31-14/checkpoint-939/tokenizer_config.json\n",
            "[flaml.automl: 08-17 15:33:42] {3242} INFO - Estimated sufficient time budget=9972946s. Estimated necessary time budget=9973s.\n",
            "INFO:flaml.automl:Estimated sufficient time budget=9972946s. Estimated necessary time budget=9973s.\n",
            "[flaml.automl: 08-17 15:33:42] {3294} INFO -  at 148.2s,\testimator transformer's best error=0.1640,\tbest estimator transformer's best error=0.1640\n",
            "INFO:flaml.automl: at 148.2s,\testimator transformer's best error=0.1640,\tbest estimator transformer's best error=0.1640\n",
            "[flaml.automl: 08-17 15:33:42] {3108} INFO - iteration 1, current learner transformer\n",
            "INFO:flaml.automl:iteration 1, current learner transformer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.4843566119670868, 'eval_automl_metric': 0.18233944954128445, 'eval_runtime': 17.7718, 'eval_samples_per_second': 49.067, 'eval_steps_per_second': 49.067, 'epoch': 2.0}\n",
            "{'eval_loss': 0.4618024230003357, 'eval_automl_metric': 0.17889908256880738, 'eval_runtime': 17.7586, 'eval_samples_per_second': 49.103, 'eval_steps_per_second': 49.103, 'epoch': 3.0}\n",
            "{'train_runtime': 79.3792, 'train_samples_per_second': 377.933, 'train_steps_per_second': 5.934, 'train_loss': 0.5575582905180135, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 872\n",
            "  Batch size = 1\n",
            "Didn't find file data/output/train_2022-08-17_15-33-42/train_f9b9cc4a_7_s=9223372036854775807,e=9.7119e-06,s=-1,s=3,e=64,d=14_2022-08-17_15-33-42/checkpoint-471/added_tokens.json. We won't load it.\n",
            "loading file data/output/train_2022-08-17_15-33-42/train_f9b9cc4a_7_s=9223372036854775807,e=9.7119e-06,s=-1,s=3,e=64,d=14_2022-08-17_15-33-42/checkpoint-471/vocab.txt\n",
            "loading file data/output/train_2022-08-17_15-33-42/train_f9b9cc4a_7_s=9223372036854775807,e=9.7119e-06,s=-1,s=3,e=64,d=14_2022-08-17_15-33-42/checkpoint-471/tokenizer.json\n",
            "loading file None\n",
            "loading file data/output/train_2022-08-17_15-33-42/train_f9b9cc4a_7_s=9223372036854775807,e=9.7119e-06,s=-1,s=3,e=64,d=14_2022-08-17_15-33-42/checkpoint-471/special_tokens_map.json\n",
            "loading file data/output/train_2022-08-17_15-33-42/train_f9b9cc4a_7_s=9223372036854775807,e=9.7119e-06,s=-1,s=3,e=64,d=14_2022-08-17_15-33-42/checkpoint-471/tokenizer_config.json\n",
            "[flaml.automl: 08-17 15:35:56] {3294} INFO -  at 281.8s,\testimator transformer's best error=0.1640,\tbest estimator transformer's best error=0.1640\n",
            "INFO:flaml.automl: at 281.8s,\testimator transformer's best error=0.1640,\tbest estimator transformer's best error=0.1640\n",
            "[flaml.automl: 08-17 15:35:56] {3108} INFO - iteration 2, current learner transformer\n",
            "INFO:flaml.automl:iteration 2, current learner transformer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.5778, 'learning_rate': 7.550901222797876e-06, 'epoch': 0.8}\n",
            "{'loss': 0.3836, 'learning_rate': 4.805118959962285e-06, 'epoch': 1.6}\n",
            "{'eval_loss': 0.37492236495018005, 'eval_automl_metric': 0.15596330275229353, 'eval_runtime': 17.6373, 'eval_samples_per_second': 49.441, 'eval_steps_per_second': 49.441, 'epoch': 2.0}\n",
            "{'loss': 0.3399, 'learning_rate': 2.0593366971266936e-06, 'epoch': 2.4}\n",
            "{'eval_loss': 0.36893224716186523, 'eval_automl_metric': 0.1490825688073395, 'eval_runtime': 17.6324, 'eval_samples_per_second': 49.454, 'eval_steps_per_second': 49.454, 'epoch': 2.69}\n",
            "{'eval_loss': 0.36893224716186523, 'eval_automl_metric': 0.1490825688073395, 'eval_runtime': 17.6783, 'eval_samples_per_second': 49.326, 'eval_steps_per_second': 49.326, 'epoch': 2.69}\n",
            "{'train_runtime': 148.8113, 'train_samples_per_second': 201.598, 'train_steps_per_second': 12.6, 'train_loss': 0.4216383731726444, 'epoch': 2.69}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 872\n",
            "  Batch size = 1\n",
            "Didn't find file data/output/train_2022-08-17_15-35-56/train_49615a9c_8_s=9223372036854775807,e=1.0297e-05,s=-1,s=3,e=16,d=26_2022-08-17_15-35-56/checkpoint-1683/added_tokens.json. We won't load it.\n",
            "loading file data/output/train_2022-08-17_15-35-56/train_49615a9c_8_s=9223372036854775807,e=1.0297e-05,s=-1,s=3,e=16,d=26_2022-08-17_15-35-56/checkpoint-1683/vocab.txt\n",
            "loading file data/output/train_2022-08-17_15-35-56/train_49615a9c_8_s=9223372036854775807,e=1.0297e-05,s=-1,s=3,e=16,d=26_2022-08-17_15-35-56/checkpoint-1683/tokenizer.json\n",
            "loading file None\n",
            "loading file data/output/train_2022-08-17_15-35-56/train_49615a9c_8_s=9223372036854775807,e=1.0297e-05,s=-1,s=3,e=16,d=26_2022-08-17_15-35-56/checkpoint-1683/special_tokens_map.json\n",
            "loading file data/output/train_2022-08-17_15-35-56/train_49615a9c_8_s=9223372036854775807,e=1.0297e-05,s=-1,s=3,e=16,d=26_2022-08-17_15-35-56/checkpoint-1683/tokenizer_config.json\n",
            "[flaml.automl: 08-17 15:39:19] {729} WARNING - checkpoint data/output/train_2022-08-17_15-31-14/train_a173ec96_6_s=9223372036854775807,e=1e-05,s=-1,s=3,e=32,d=20_2022-08-17_15-31-14/checkpoint-939 not found\n",
            "WARNING:flaml.automl:checkpoint data/output/train_2022-08-17_15-31-14/train_a173ec96_6_s=9223372036854775807,e=1e-05,s=-1,s=3,e=32,d=20_2022-08-17_15-31-14/checkpoint-939 not found\n",
            "[flaml.automl: 08-17 15:39:19] {3294} INFO -  at 484.5s,\testimator transformer's best error=0.1491,\tbest estimator transformer's best error=0.1491\n",
            "INFO:flaml.automl: at 484.5s,\testimator transformer's best error=0.1491,\tbest estimator transformer's best error=0.1491\n",
            "[flaml.automl: 08-17 15:39:19] {3108} INFO - iteration 3, current learner transformer\n",
            "INFO:flaml.automl:iteration 3, current learner transformer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.5362, 'learning_rate': 8.879996750213199e-06, 'epoch': 0.8}\n",
            "{'eval_loss': 0.3863365054130554, 'eval_automl_metric': 0.1594036697247706, 'eval_runtime': 17.7413, 'eval_samples_per_second': 49.151, 'eval_steps_per_second': 49.151, 'epoch': 1.0}\n",
            "{'loss': 0.3654, 'learning_rate': 2.959998916737733e-06, 'epoch': 1.6}\n",
            "{'eval_loss': 0.37569329142570496, 'eval_automl_metric': 0.15596330275229353, 'eval_runtime': 17.7129, 'eval_samples_per_second': 49.23, 'eval_steps_per_second': 49.23, 'epoch': 2.0}\n",
            "{'train_runtime': 106.5443, 'train_samples_per_second': 187.715, 'train_steps_per_second': 11.732, 'train_loss': 0.42628197021484376, 'epoch': 2.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 872\n",
            "  Batch size = 1\n",
            "Didn't find file data/output/train_2022-08-17_15-39-19/train_c22d193e_9_s=9223372036854775807,e=1.48e-05,s=-1,s=2,e=16,d=25_2022-08-17_15-39-19/checkpoint-1250/added_tokens.json. We won't load it.\n",
            "loading file data/output/train_2022-08-17_15-39-19/train_c22d193e_9_s=9223372036854775807,e=1.48e-05,s=-1,s=2,e=16,d=25_2022-08-17_15-39-19/checkpoint-1250/vocab.txt\n",
            "loading file data/output/train_2022-08-17_15-39-19/train_c22d193e_9_s=9223372036854775807,e=1.48e-05,s=-1,s=2,e=16,d=25_2022-08-17_15-39-19/checkpoint-1250/tokenizer.json\n",
            "loading file None\n",
            "loading file data/output/train_2022-08-17_15-39-19/train_c22d193e_9_s=9223372036854775807,e=1.48e-05,s=-1,s=2,e=16,d=25_2022-08-17_15-39-19/checkpoint-1250/special_tokens_map.json\n",
            "loading file data/output/train_2022-08-17_15-39-19/train_c22d193e_9_s=9223372036854775807,e=1.48e-05,s=-1,s=2,e=16,d=25_2022-08-17_15-39-19/checkpoint-1250/tokenizer_config.json\n",
            "[flaml.automl: 08-17 15:41:59] {3294} INFO -  at 645.1s,\testimator transformer's best error=0.1491,\tbest estimator transformer's best error=0.1491\n",
            "INFO:flaml.automl: at 645.1s,\testimator transformer's best error=0.1491,\tbest estimator transformer's best error=0.1491\n",
            "[flaml.automl: 08-17 15:41:59] {3108} INFO - iteration 4, current learner transformer\n",
            "INFO:flaml.automl:iteration 4, current learner transformer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.6402, 'learning_rate': 5.730904302906456e-06, 'epoch': 0.8}\n",
            "{'loss': 0.4537, 'learning_rate': 4.298178227179842e-06, 'epoch': 1.6}\n",
            "{'loss': 0.3716, 'learning_rate': 2.865452151453228e-06, 'epoch': 2.4}\n",
            "{'eval_loss': 0.417883962392807, 'eval_automl_metric': 0.1731651376146789, 'eval_runtime': 17.72, 'eval_samples_per_second': 49.21, 'eval_steps_per_second': 49.21, 'epoch': 2.43}\n",
            "{'eval_loss': 0.417883962392807, 'eval_automl_metric': 0.1731651376146789, 'eval_runtime': 17.5469, 'eval_samples_per_second': 49.695, 'eval_steps_per_second': 49.695, 'epoch': 2.43}\n",
            "{'train_runtime': 121.8639, 'train_samples_per_second': 328.235, 'train_steps_per_second': 20.515, 'train_loss': 0.48722538646501984, 'epoch': 2.43}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 872\n",
            "  Batch size = 1\n",
            "Didn't find file data/output/train_2022-08-17_15-41-59/train_21e49988_10_s=9223372036854775807,e=7.1636e-06,s=-1,s=4,e=16,d=27_2022-08-17_15-41-59/checkpoint-1518/added_tokens.json. We won't load it.\n",
            "loading file data/output/train_2022-08-17_15-41-59/train_21e49988_10_s=9223372036854775807,e=7.1636e-06,s=-1,s=4,e=16,d=27_2022-08-17_15-41-59/checkpoint-1518/vocab.txt\n",
            "loading file data/output/train_2022-08-17_15-41-59/train_21e49988_10_s=9223372036854775807,e=7.1636e-06,s=-1,s=4,e=16,d=27_2022-08-17_15-41-59/checkpoint-1518/tokenizer.json\n",
            "loading file None\n",
            "loading file data/output/train_2022-08-17_15-41-59/train_21e49988_10_s=9223372036854775807,e=7.1636e-06,s=-1,s=4,e=16,d=27_2022-08-17_15-41-59/checkpoint-1518/special_tokens_map.json\n",
            "loading file data/output/train_2022-08-17_15-41-59/train_21e49988_10_s=9223372036854775807,e=7.1636e-06,s=-1,s=4,e=16,d=27_2022-08-17_15-41-59/checkpoint-1518/tokenizer_config.json\n",
            "[flaml.automl: 08-17 15:44:55] {3294} INFO -  at 820.5s,\testimator transformer's best error=0.1491,\tbest estimator transformer's best error=0.1491\n",
            "INFO:flaml.automl: at 820.5s,\testimator transformer's best error=0.1491,\tbest estimator transformer's best error=0.1491\n",
            "[flaml.automl: 08-17 15:44:55] {3108} INFO - iteration 5, current learner transformer\n",
            "INFO:flaml.automl:iteration 5, current learner transformer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.5223, 'learning_rate': 1.3121346786922505e-05, 'epoch': 0.8}\n",
            "{'loss': 0.333, 'learning_rate': 8.349947955314322e-06, 'epoch': 1.6}\n",
            "{'eval_loss': 0.3744150698184967, 'eval_automl_metric': 0.16169724770642202, 'eval_runtime': 17.5601, 'eval_samples_per_second': 49.658, 'eval_steps_per_second': 49.658, 'epoch': 2.0}\n",
            "{'eval_loss': 0.37506288290023804, 'eval_automl_metric': 0.16169724770642202, 'eval_runtime': 17.5115, 'eval_samples_per_second': 49.796, 'eval_steps_per_second': 49.796, 'epoch': 2.0}\n",
            "{'eval_loss': 0.37506288290023804, 'eval_automl_metric': 0.16169724770642202, 'eval_runtime': 17.8345, 'eval_samples_per_second': 48.894, 'eval_steps_per_second': 48.894, 'epoch': 2.0}\n",
            "{'train_runtime': 123.7249, 'train_samples_per_second': 242.473, 'train_steps_per_second': 15.155, 'train_loss': 0.4039465510111442, 'epoch': 2.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 872\n",
            "  Batch size = 1\n",
            "Didn't find file data/output/train_2022-08-17_15-44-55/train_8a78ee7c_11_s=9223372036854775807,e=1.7893e-05,s=-1,s=3,e=16,d=32_2022-08-17_15-44-55/checkpoint-1250/added_tokens.json. We won't load it.\n",
            "loading file data/output/train_2022-08-17_15-44-55/train_8a78ee7c_11_s=9223372036854775807,e=1.7893e-05,s=-1,s=3,e=16,d=32_2022-08-17_15-44-55/checkpoint-1250/vocab.txt\n",
            "loading file data/output/train_2022-08-17_15-44-55/train_8a78ee7c_11_s=9223372036854775807,e=1.7893e-05,s=-1,s=3,e=16,d=32_2022-08-17_15-44-55/checkpoint-1250/tokenizer.json\n",
            "loading file None\n",
            "loading file data/output/train_2022-08-17_15-44-55/train_8a78ee7c_11_s=9223372036854775807,e=1.7893e-05,s=-1,s=3,e=16,d=32_2022-08-17_15-44-55/checkpoint-1250/special_tokens_map.json\n",
            "loading file data/output/train_2022-08-17_15-44-55/train_8a78ee7c_11_s=9223372036854775807,e=1.7893e-05,s=-1,s=3,e=16,d=32_2022-08-17_15-44-55/checkpoint-1250/tokenizer_config.json\n",
            "[flaml.automl: 08-17 15:47:53] {3294} INFO -  at 998.6s,\testimator transformer's best error=0.1491,\tbest estimator transformer's best error=0.1491\n",
            "INFO:flaml.automl: at 998.6s,\testimator transformer's best error=0.1491,\tbest estimator transformer's best error=0.1491\n",
            "[flaml.automl: 08-17 15:47:53] {3108} INFO - iteration 6, current learner transformer\n",
            "INFO:flaml.automl:iteration 6, current learner transformer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.6593, 'learning_rate': 4.3452939856201385e-06, 'epoch': 0.8}\n",
            "{'loss': 0.5039, 'learning_rate': 2.76518708175827e-06, 'epoch': 1.6}\n",
            "{'eval_loss': 0.45492106676101685, 'eval_automl_metric': 0.18463302752293576, 'eval_runtime': 17.8382, 'eval_samples_per_second': 48.884, 'eval_steps_per_second': 48.884, 'epoch': 1.69}\n",
            "{'eval_loss': 0.45492106676101685, 'eval_automl_metric': 0.18463302752293576, 'eval_runtime': 17.6594, 'eval_samples_per_second': 49.379, 'eval_steps_per_second': 49.379, 'epoch': 1.69}\n",
            "{'train_runtime': 95.8461, 'train_samples_per_second': 313.002, 'train_steps_per_second': 19.563, 'train_loss': 0.5738005016161047, 'epoch': 1.69}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 872\n",
            "  Batch size = 1\n",
            "Didn't find file data/output/train_2022-08-17_15-47-53/train_f4a27994_12_s=9223372036854775807,e=5.9254e-06,s=-1,s=3,e=16,d=20_2022-08-17_15-47-53/checkpoint-1058/added_tokens.json. We won't load it.\n",
            "loading file data/output/train_2022-08-17_15-47-53/train_f4a27994_12_s=9223372036854775807,e=5.9254e-06,s=-1,s=3,e=16,d=20_2022-08-17_15-47-53/checkpoint-1058/vocab.txt\n",
            "loading file data/output/train_2022-08-17_15-47-53/train_f4a27994_12_s=9223372036854775807,e=5.9254e-06,s=-1,s=3,e=16,d=20_2022-08-17_15-47-53/checkpoint-1058/tokenizer.json\n",
            "loading file None\n",
            "loading file data/output/train_2022-08-17_15-47-53/train_f4a27994_12_s=9223372036854775807,e=5.9254e-06,s=-1,s=3,e=16,d=20_2022-08-17_15-47-53/checkpoint-1058/special_tokens_map.json\n",
            "loading file data/output/train_2022-08-17_15-47-53/train_f4a27994_12_s=9223372036854775807,e=5.9254e-06,s=-1,s=3,e=16,d=20_2022-08-17_15-47-53/checkpoint-1058/tokenizer_config.json\n",
            "[flaml.automl: 08-17 15:50:23] {3294} INFO -  at 1148.4s,\testimator transformer's best error=0.1491,\tbest estimator transformer's best error=0.1491\n",
            "INFO:flaml.automl: at 1148.4s,\testimator transformer's best error=0.1491,\tbest estimator transformer's best error=0.1491\n",
            "[flaml.automl: 08-17 15:50:23] {3108} INFO - iteration 7, current learner transformer\n",
            "INFO:flaml.automl:iteration 7, current learner transformer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.4949, 'learning_rate': 1.624682269684853e-05, 'epoch': 0.8}\n",
            "{'eval_loss': 0.4377938508987427, 'eval_automl_metric': 0.1651376146788991, 'eval_runtime': 17.5955, 'eval_samples_per_second': 49.558, 'eval_steps_per_second': 49.558, 'epoch': 1.38}\n",
            "{'eval_loss': 0.4377938508987427, 'eval_automl_metric': 0.1651376146788991, 'eval_runtime': 17.8456, 'eval_samples_per_second': 48.864, 'eval_steps_per_second': 48.864, 'epoch': 1.38}\n",
            "{'train_runtime': 84.7139, 'train_samples_per_second': 354.133, 'train_steps_per_second': 22.133, 'train_loss': 0.424861603665214, 'epoch': 1.38}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 872\n",
            "  Batch size = 1\n",
            "Didn't find file data/output/train_2022-08-17_15-50-23/train_4de5ec2a_13_s=9223372036854775807,e=2.2155e-05,s=-1,s=3,e=16,d=24_2022-08-17_15-50-23/checkpoint-865/added_tokens.json. We won't load it.\n",
            "loading file data/output/train_2022-08-17_15-50-23/train_4de5ec2a_13_s=9223372036854775807,e=2.2155e-05,s=-1,s=3,e=16,d=24_2022-08-17_15-50-23/checkpoint-865/vocab.txt\n",
            "loading file data/output/train_2022-08-17_15-50-23/train_4de5ec2a_13_s=9223372036854775807,e=2.2155e-05,s=-1,s=3,e=16,d=24_2022-08-17_15-50-23/checkpoint-865/tokenizer.json\n",
            "loading file None\n",
            "loading file data/output/train_2022-08-17_15-50-23/train_4de5ec2a_13_s=9223372036854775807,e=2.2155e-05,s=-1,s=3,e=16,d=24_2022-08-17_15-50-23/checkpoint-865/special_tokens_map.json\n",
            "loading file data/output/train_2022-08-17_15-50-23/train_4de5ec2a_13_s=9223372036854775807,e=2.2155e-05,s=-1,s=3,e=16,d=24_2022-08-17_15-50-23/checkpoint-865/tokenizer_config.json\n",
            "[flaml.automl: 08-17 15:52:42] {3294} INFO -  at 1287.3s,\testimator transformer's best error=0.1491,\tbest estimator transformer's best error=0.1491\n",
            "INFO:flaml.automl: at 1287.3s,\testimator transformer's best error=0.1491,\tbest estimator transformer's best error=0.1491\n",
            "[flaml.automl: 08-17 15:52:42] {3108} INFO - iteration 8, current learner transformer\n",
            "INFO:flaml.automl:iteration 8, current learner transformer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.6603, 'learning_rate': 3.5093698220458912e-06, 'epoch': 0.8}\n",
            "{'eval_loss': 0.5574597120285034, 'eval_automl_metric': 0.231651376146789, 'eval_runtime': 17.6262, 'eval_samples_per_second': 49.472, 'eval_steps_per_second': 49.472, 'epoch': 1.08}\n",
            "{'eval_loss': 0.5574597120285034, 'eval_automl_metric': 0.231651376146789, 'eval_runtime': 17.6524, 'eval_samples_per_second': 49.398, 'eval_steps_per_second': 49.398, 'epoch': 1.08}\n",
            "{'train_runtime': 74.1762, 'train_samples_per_second': 404.442, 'train_steps_per_second': 25.278, 'train_loss': 0.6372765735187361, 'epoch': 1.08}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 872\n",
            "  Batch size = 1\n",
            "Didn't find file data/output/train_2022-08-17_15-52-42/train_a0b9429e_14_s=9223372036854775807,e=4.7855e-06,s=-1,s=3,e=16,d=28_2022-08-17_15-52-42/checkpoint-678/added_tokens.json. We won't load it.\n",
            "loading file data/output/train_2022-08-17_15-52-42/train_a0b9429e_14_s=9223372036854775807,e=4.7855e-06,s=-1,s=3,e=16,d=28_2022-08-17_15-52-42/checkpoint-678/vocab.txt\n",
            "loading file data/output/train_2022-08-17_15-52-42/train_a0b9429e_14_s=9223372036854775807,e=4.7855e-06,s=-1,s=3,e=16,d=28_2022-08-17_15-52-42/checkpoint-678/tokenizer.json\n",
            "loading file None\n",
            "loading file data/output/train_2022-08-17_15-52-42/train_a0b9429e_14_s=9223372036854775807,e=4.7855e-06,s=-1,s=3,e=16,d=28_2022-08-17_15-52-42/checkpoint-678/special_tokens_map.json\n",
            "loading file data/output/train_2022-08-17_15-52-42/train_a0b9429e_14_s=9223372036854775807,e=4.7855e-06,s=-1,s=3,e=16,d=28_2022-08-17_15-52-42/checkpoint-678/tokenizer_config.json\n",
            "[flaml.automl: 08-17 15:54:50] {3294} INFO -  at 1415.6s,\testimator transformer's best error=0.1491,\tbest estimator transformer's best error=0.1491\n",
            "INFO:flaml.automl: at 1415.6s,\testimator transformer's best error=0.1491,\tbest estimator transformer's best error=0.1491\n",
            "[flaml.automl: 08-17 15:54:50] {3108} INFO - iteration 9, current learner transformer\n",
            "INFO:flaml.automl:iteration 9, current learner transformer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.569, 'learning_rate': 9.889055477492793e-06, 'epoch': 0.12}\n",
            "{'loss': 0.3883, 'learning_rate': 9.481427469352118e-06, 'epoch': 0.24}\n",
            "{'loss': 0.3417, 'learning_rate': 9.073799461211442e-06, 'epoch': 0.36}\n",
            "{'loss': 0.3214, 'learning_rate': 8.666171453070765e-06, 'epoch': 0.48}\n",
            "{'loss': 0.2934, 'learning_rate': 8.25854344493009e-06, 'epoch': 0.59}\n",
            "{'loss': 0.2847, 'learning_rate': 7.850915436789415e-06, 'epoch': 0.71}\n",
            "{'loss': 0.2737, 'learning_rate': 7.443287428648738e-06, 'epoch': 0.83}\n",
            "{'loss': 0.2676, 'learning_rate': 7.035659420508063e-06, 'epoch': 0.95}\n",
            "{'loss': 0.2502, 'learning_rate': 6.628031412367387e-06, 'epoch': 1.07}\n",
            "{'loss': 0.2328, 'learning_rate': 6.220403404226712e-06, 'epoch': 1.19}\n",
            "{'loss': 0.2443, 'learning_rate': 5.812775396086035e-06, 'epoch': 1.31}\n",
            "{'loss': 0.2288, 'learning_rate': 5.405147387945359e-06, 'epoch': 1.43}\n",
            "{'loss': 0.2243, 'learning_rate': 4.997519379804684e-06, 'epoch': 1.54}\n",
            "{'eval_loss': 0.2805942893028259, 'eval_automl_metric': 0.08600917431192656, 'eval_runtime': 17.4177, 'eval_samples_per_second': 50.064, 'eval_steps_per_second': 50.064, 'epoch': 1.65}\n",
            "{'eval_loss': 0.2805942893028259, 'eval_automl_metric': 0.08600917431192656, 'eval_runtime': 17.502, 'eval_samples_per_second': 49.823, 'eval_steps_per_second': 49.823, 'epoch': 1.65}\n",
            "{'train_runtime': 420.1131, 'train_samples_per_second': 480.935, 'train_steps_per_second': 30.063, 'train_loss': 0.2966508084466121, 'epoch': 1.65}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 872\n",
            "  Batch size = 1\n",
            "Didn't find file data/output/train_2022-08-17_15-54-50/train_ed2de38c_15_s=9223372036854775807,e=1.0297e-05,s=-1,s=3,e=16,d=26_2022-08-17_15-54-50/checkpoint-6949/added_tokens.json. We won't load it.\n",
            "loading file data/output/train_2022-08-17_15-54-50/train_ed2de38c_15_s=9223372036854775807,e=1.0297e-05,s=-1,s=3,e=16,d=26_2022-08-17_15-54-50/checkpoint-6949/vocab.txt\n",
            "loading file data/output/train_2022-08-17_15-54-50/train_ed2de38c_15_s=9223372036854775807,e=1.0297e-05,s=-1,s=3,e=16,d=26_2022-08-17_15-54-50/checkpoint-6949/tokenizer.json\n",
            "loading file None\n",
            "loading file data/output/train_2022-08-17_15-54-50/train_ed2de38c_15_s=9223372036854775807,e=1.0297e-05,s=-1,s=3,e=16,d=26_2022-08-17_15-54-50/checkpoint-6949/special_tokens_map.json\n",
            "loading file data/output/train_2022-08-17_15-54-50/train_ed2de38c_15_s=9223372036854775807,e=1.0297e-05,s=-1,s=3,e=16,d=26_2022-08-17_15-54-50/checkpoint-6949/tokenizer_config.json\n",
            "[flaml.automl: 08-17 16:03:09] {729} WARNING - checkpoint data/output/train_2022-08-17_15-35-56/train_49615a9c_8_s=9223372036854775807,e=1.0297e-05,s=-1,s=3,e=16,d=26_2022-08-17_15-35-56/checkpoint-1683 not found\n",
            "WARNING:flaml.automl:checkpoint data/output/train_2022-08-17_15-35-56/train_49615a9c_8_s=9223372036854775807,e=1.0297e-05,s=-1,s=3,e=16,d=26_2022-08-17_15-35-56/checkpoint-1683 not found\n",
            "[flaml.automl: 08-17 16:03:09] {3294} INFO -  at 1914.8s,\testimator transformer's best error=0.0860,\tbest estimator transformer's best error=0.0860\n",
            "INFO:flaml.automl: at 1914.8s,\testimator transformer's best error=0.0860,\tbest estimator transformer's best error=0.0860\n",
            "[flaml.automl: 08-17 16:03:09] {3409} INFO - selected model: None\n",
            "INFO:flaml.automl:selected model: None\n",
            "[flaml.automl: 08-17 16:03:09] {2837} INFO - fit succeeded\n",
            "INFO:flaml.automl:fit succeeded\n",
            "[flaml.automl: 08-17 16:03:09] {2839} INFO - Time taken to find the best model: 1914.8284049034119\n",
            "INFO:flaml.automl:Time taken to find the best model: 1914.8284049034119\n",
            "[flaml.automl: 08-17 16:03:09] {2853} WARNING - Time taken to find the best model is 106% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
            "WARNING:flaml.automl:Time taken to find the best model is 106% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
          ]
        }
      ],
      "source": [
        "'''The main flaml automl API'''\n",
        "automl.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **automl_settings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can print the best trial's loss, which is 1-the accuracy. The accuracy we got is 91.4% which is better than 91.2% reported by [the Electra model github](https://github.com/google-research/electra). "
      ],
      "metadata": {
        "id": "Ehn1SDb5xAH9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbTAqBsnTjhG",
        "outputId": "f9214538-da65-4ce3-b2b9-79cb1ed031e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best loss by FLAML: 0.08600917431192656\n"
          ]
        }
      ],
      "source": [
        "print(\"The best loss by FLAML: {}\".format(automl.best_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have more GPUs on your server, you can use flaml.tune with the ray tune option, which will often give you a better score. For example, with the 4 NVIDIA V100 GPUs, the accuracy was 92.2%. For that experiment, you can open this notebook on your GPU server and set \"use_ray\" to {\"local_dir\": \"data/output/\"} and n_concurrent_trials to more than 1. "
      ],
      "metadata": {
        "id": "wcO2th5M6AIu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFP5JNdPTjhG"
      },
      "source": [
        "### Best model and metric"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can print the best hyperparameter and the best score:"
      ],
      "metadata": {
        "id": "mY07pTY_xlIV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbnhP3WrTjhG",
        "outputId": "6432a60b-30bf-4578-bf77-3f54cd196e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparmeter config: {'learning_rate': 1.0296683485633468e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'seed': 26, 'global_max_steps': 6949, 'FLAML_sample_size': 67349}\n",
            "Best accuracy on validation data: 0.914\n",
            "Training duration of best run: 499.2 s\n"
          ]
        }
      ],
      "source": [
        "'''retrieve best config and best learner'''\n",
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model:"
      ],
      "metadata": {
        "id": "Vmm6EOr-xsZS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6LspsxzTjhH",
        "outputId": "84333985-8614-42c8-e662-6ffaf706a837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 08-17 17:20:19] {729} WARNING - checkpoint data/output/train_2022-08-17_15-54-50/train_ed2de38c_15_s=9223372036854775807,e=1.0297e-05,s=-1,s=3,e=16,d=26_2022-08-17_15-54-50/checkpoint-6949 not found\n",
            "WARNING:flaml.automl:checkpoint data/output/train_2022-08-17_15-54-50/train_ed2de38c_15_s=9223372036854775807,e=1.0297e-05,s=-1,s=3,e=16,d=26_2022-08-17_15-54-50/checkpoint-6949 not found\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "automl.pickle(\"automl.pkl\")\n",
        "\n",
        "with open(\"automl.pkl\", \"rb\") as f:\n",
        "    automl = pickle.load(f)\n",
        "\n",
        "print(automl._trained_estimator.model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And print the predicted labels:"
      ],
      "metadata": {
        "id": "6mdBURdexxJS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "kRl7pnEKTjhH",
        "outputId": "c54c5f01-da88-4cee-87ba-7c955ecc44ef"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-2c26d0a7f8db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m'''compute predictions of testing dataset'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"per_device_eval_batch_size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flaml/automl.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **pred_kwargs)\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpred_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m         if (\n\u001b[1;32m    934\u001b[0m             \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flaml/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **pred_kwargs)\u001b[0m\n\u001b[1;32m    862\u001b[0m                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m         \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m         \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flaml/model.py\u001b[0m in \u001b[0;36m_tokenize_text\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m                 \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m                 \u001b[0mhf_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                 \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m             )\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flaml/model.py\u001b[0m in \u001b[0;36mtokenizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                 \u001b[0madd_prefix_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_prefix_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             )\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m         \u001b[0mconfig_tokenizer_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizer_class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mtokenizer_auto_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m     )\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresolved_config_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mget_file_from_repo\u001b[0;34m(path_or_repo, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only)\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mresume_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         )\n\u001b[1;32m    292\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                     raise ValueError(\n\u001b[0;32m--> 546\u001b[0;31m                         \u001b[0;34m\"Connection error, and we cannot find the requested files in the cached path.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m                         \u001b[0;34m\" Please try again or make sure your Internet connection is on.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                     )\n",
            "\u001b[0;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on."
          ]
        }
      ],
      "source": [
        "'''compute predictions of testing dataset''' \n",
        "y_pred = automl.predict(X_val, **{\"per_device_eval_batch_size\": 1})\n",
        "print('Predicted labels', y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QThcVssKTjhH"
      },
      "source": [
        "### Log history"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also save and plot the history:"
      ],
      "metadata": {
        "id": "OEFqWAuLyYIQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58wpj4vPTjhH",
        "outputId": "c916960f-d8eb-49a7-e283-6e37c67abff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 9.999999999999999e-06, 'num_train_epochs': 3, 'per_device_train_batch_size': 32, 'seed': 20, 'global_max_steps': 939, 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 9.999999999999999e-06, 'num_train_epochs': 3, 'per_device_train_batch_size': 32, 'seed': 20, 'global_max_steps': 939, 'FLAML_sample_size': 10000}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 9.711865003865157e-06, 'num_train_epochs': 3, 'per_device_train_batch_size': 64, 'seed': 14, 'global_max_steps': 471, 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 9.999999999999999e-06, 'num_train_epochs': 3, 'per_device_train_batch_size': 32, 'seed': 20, 'global_max_steps': 939, 'FLAML_sample_size': 10000}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.0296683485633468e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'seed': 26, 'global_max_steps': 1683, 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0296683485633468e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'seed': 26, 'global_max_steps': 1683, 'FLAML_sample_size': 10000}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.4799994583688665e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 16, 'seed': 25, 'global_max_steps': 1250, 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0296683485633468e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'seed': 26, 'global_max_steps': 1683, 'FLAML_sample_size': 10000}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 7.163630378633069e-06, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'seed': 27, 'global_max_steps': 1518, 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0296683485633468e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'seed': 26, 'global_max_steps': 1683, 'FLAML_sample_size': 10000}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.789274561853069e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'seed': 32, 'global_max_steps': 1250, 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0296683485633468e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'seed': 26, 'global_max_steps': 1683, 'FLAML_sample_size': 10000}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 5.925400889482007e-06, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'seed': 20, 'global_max_steps': 1058, 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0296683485633468e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'seed': 26, 'global_max_steps': 1683, 'FLAML_sample_size': 10000}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 2.215475822297527e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'seed': 24, 'global_max_steps': 865, 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0296683485633468e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'seed': 26, 'global_max_steps': 1683, 'FLAML_sample_size': 10000}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 4.785504302789852e-06, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'seed': 28, 'global_max_steps': 678, 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0296683485633468e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'seed': 26, 'global_max_steps': 1683, 'FLAML_sample_size': 10000}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 67349, 'Current Hyper-parameters': {'learning_rate': 1.0296683485633468e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'seed': 26, 'global_max_steps': 6949, 'FLAML_sample_size': 67349}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0296683485633468e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'seed': 26, 'global_max_steps': 6949, 'FLAML_sample_size': 67349}}\n"
          ]
        }
      ],
      "source": [
        "from flaml.data import get_output_from_log\n",
        "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
        "    get_output_from_log(filename=automl_settings['log_file_name'], time_budget=3000)\n",
        "for config in config_history:\n",
        "    print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "dtWSrLsdTjhH",
        "outputId": "d7fd192d-de86-484a-9585-43f919b0e8d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Wall Clock Time (s)')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "print(len(valid_loss_history))\n",
        "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
        "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xudzM73mTjhI"
      },
      "source": [
        "## 3. Spooky-author-identification example"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we will tune the [spooky-author-identification](https://www.kaggle.com/competitions/spooky-author-identification/data?select=train.zip) dataset from kaggle. First, you can download the dataset from the website and upload it to Colab. We run FLAML for 30 mins using bert."
      ],
      "metadata": {
        "id": "A3gC3u_E4cO1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjvdojhfTjhI",
        "outputId": "3d48de50-a762-44c9-ccd8-46d97a0221c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 08-17 18:08:14] {2540} INFO - task = seq-classification\n",
            "INFO:flaml.automl:task = seq-classification\n",
            "[flaml.automl: 08-17 18:08:14] {2542} INFO - Data split method: stratified\n",
            "INFO:flaml.automl:Data split method: stratified\n",
            "[flaml.automl: 08-17 18:08:14] {2545} INFO - Evaluation method: holdout\n",
            "INFO:flaml.automl:Evaluation method: holdout\n",
            "[flaml.automl: 08-17 18:08:14] {2664} INFO - Minimizing error metric: 1-accuracy\n",
            "INFO:flaml.automl:Minimizing error metric: 1-accuracy\n",
            "[flaml.automl: 08-17 18:08:14] {2806} INFO - List of ML learners in AutoML Run: ['transformer']\n",
            "INFO:flaml.automl:List of ML learners in AutoML Run: ['transformer']\n",
            "[flaml.automl: 08-17 18:08:14] {3108} INFO - iteration 0, current learner transformer\n",
            "INFO:flaml.automl:iteration 0, current learner transformer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14684 4895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.6753, 'learning_rate': 6.368917937545388e-06, 'epoch': 1.09}\n",
            "{'eval_loss': 0.40918204188346863, 'eval_automl_metric': 0.15587334014300303, 'eval_runtime': 57.3366, 'eval_samples_per_second': 85.373, 'eval_steps_per_second': 85.373, 'epoch': 2.0}\n",
            "{'loss': 0.3702, 'learning_rate': 2.737835875090777e-06, 'epoch': 2.18}\n",
            "{'eval_loss': 0.40416425466537476, 'eval_automl_metric': 0.1485188968335036, 'eval_runtime': 58.4248, 'eval_samples_per_second': 83.783, 'eval_steps_per_second': 83.783, 'epoch': 3.0}\n",
            "{'train_runtime': 885.4648, 'train_samples_per_second': 49.75, 'train_steps_per_second': 1.555, 'train_loss': 0.45735700353817743, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 4895\n",
            "  Batch size = 1\n",
            "Didn't find file data/output/train_2022-08-17_18-08-14/train_9016f8ce_2_s=9223372036854775807,e=1e-05,s=-1,s=3,e=32,d=20_2022-08-17_18-08-14/checkpoint-1377/added_tokens.json. We won't load it.\n",
            "loading file data/output/train_2022-08-17_18-08-14/train_9016f8ce_2_s=9223372036854775807,e=1e-05,s=-1,s=3,e=32,d=20_2022-08-17_18-08-14/checkpoint-1377/vocab.txt\n",
            "loading file data/output/train_2022-08-17_18-08-14/train_9016f8ce_2_s=9223372036854775807,e=1e-05,s=-1,s=3,e=32,d=20_2022-08-17_18-08-14/checkpoint-1377/tokenizer.json\n",
            "loading file None\n",
            "loading file data/output/train_2022-08-17_18-08-14/train_9016f8ce_2_s=9223372036854775807,e=1e-05,s=-1,s=3,e=32,d=20_2022-08-17_18-08-14/checkpoint-1377/special_tokens_map.json\n",
            "loading file data/output/train_2022-08-17_18-08-14/train_9016f8ce_2_s=9223372036854775807,e=1e-05,s=-1,s=3,e=32,d=20_2022-08-17_18-08-14/checkpoint-1377/tokenizer_config.json\n",
            "[flaml.automl: 08-17 18:24:10] {3242} INFO - Estimated sufficient time budget=9561620s. Estimated necessary time budget=9562s.\n",
            "INFO:flaml.automl:Estimated sufficient time budget=9561620s. Estimated necessary time budget=9562s.\n",
            "[flaml.automl: 08-17 18:24:10] {3294} INFO -  at 956.2s,\testimator transformer's best error=0.1485,\tbest estimator transformer's best error=0.1485\n",
            "INFO:flaml.automl: at 956.2s,\testimator transformer's best error=0.1485,\tbest estimator transformer's best error=0.1485\n",
            "[flaml.automl: 08-17 18:24:10] {3409} INFO - selected model: None\n",
            "INFO:flaml.automl:selected model: None\n",
            "[flaml.automl: 08-17 18:24:10] {2837} INFO - fit succeeded\n",
            "INFO:flaml.automl:fit succeeded\n",
            "[flaml.automl: 08-17 18:24:10] {2839} INFO - Time taken to find the best model: 956.242506980896\n",
            "INFO:flaml.automl:Time taken to find the best model: 956.242506980896\n"
          ]
        }
      ],
      "source": [
        "import flaml\n",
        "from flaml import AutoML\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('spooky-author-identification.csv')\n",
        "X, y = df.drop('author', axis=1), df['author']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=123)\n",
        "\n",
        "\n",
        "print(len(X_train), len(X_val))\n",
        "automl_model = AutoML()\n",
        "\n",
        "automl_settings = {\n",
        "    \"time_budget\": 1800,                 \n",
        "    \"task\": \"seq-classification\",       \n",
        "    \"fit_kwargs_by_estimator\": {\n",
        "        \"transformer\": {\n",
        "            \"output_dir\": \"data/output/\",   \n",
        "            \"model_path\": \"bert-base-uncased\",  \n",
        "        }\n",
        "    },\n",
        "    \"metric\": \"accuracy\",\n",
        "    \"gpu_per_trial\": 1,  \n",
        "    \"log_file_name\": \"spooky_bert.log\", \n",
        "    \"log_type\": \"all\",                 \n",
        "    \"use_ray\": False,                    # set whether to use Ray\n",
        "    \"n_concurrent_trials\": 1,\n",
        "    \"keep_search_state\": True,          # keeping the search state\n",
        "}\n",
        "\n",
        "automl_model.fit(X_train=X_train, y_train=y_train,X_val=X_val, y_val=y_val, **automl_settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpA-rzYzTjhI",
        "outputId": "f507d1cc-5039-49dd-f4c1-2c752933574d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the best loss for spooky author identification: 0.11133810010214507\n"
          ]
        }
      ],
      "source": [
        "print(\"the best loss for spooky author identification: {}\".format(automl_model.best_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MTZCJz1TjhJ",
        "outputId": "f0060992-6929-4668-cc2a-2c1af4b72953"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-07-21 21:21:15 (running for 00:30:10.30)<br>Memory usage on this node: 20.5/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/4 CPUs, 0/4 GPUs, 0.0/252.62 GiB heap, 0.0/112.26 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: 84d3be85 with val_loss=0.12951991828396325 and parameters={'learning_rate': 4.486769916716146e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 8, 'seed': 28, 'global_max_steps': 9223372036854775807, 'learner': 'transformer'}<br>Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05<br>Number of trials: 12/1000000 (12 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m {'eval_loss': 0.7418951392173767, 'eval_automl_metric': 0.1284984678243105, 'eval_runtime': 37.3935, 'eval_samples_per_second': 130.905, 'eval_steps_per_second': 130.905, 'epoch': 4.0}\n",
            "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m {'train_runtime': 565.7729, 'train_samples_per_second': 103.816, 'train_steps_per_second': 6.49, 'train_loss': 0.2802804773409642, 'epoch': 4.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m ***** Running Prediction *****\n",
            "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m   Num examples = 4895\n",
            "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m   Batch size = 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m {'eval_loss': 1.0893423557281494, 'eval_automl_metric': 0.6024514811031665, 'eval_runtime': 39.7178, 'eval_samples_per_second': 123.245, 'eval_steps_per_second': 123.245, 'epoch': 3.0}\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.2369, 'learning_rate': 1.4090340380281214e-05, 'epoch': 2.72}\n",
            "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m {'train_runtime': 566.9953, 'train_samples_per_second': 77.694, 'train_steps_per_second': 9.714, 'train_loss': 1.0928592581461545, 'epoch': 3.0}\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'eval_loss': 1.092341661453247, 'eval_automl_metric': 0.6024514811031665, 'eval_runtime': 38.0057, 'eval_samples_per_second': 128.797, 'eval_steps_per_second': 128.797, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m ***** Running Prediction *****\n",
            "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m   Num examples = 4895\n",
            "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m   Batch size = 1\n",
            "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m Didn't find file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_60247332_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_21-11-36/checkpoint-3672/added_tokens.json. We won't load it.\n",
            "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_60247332_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_21-11-36/checkpoint-3672/vocab.json\n",
            "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_60247332_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_21-11-36/checkpoint-3672/merges.txt\n",
            "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_60247332_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_21-11-36/checkpoint-3672/tokenizer.json\n",
            "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m loading file None\n",
            "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_60247332_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_21-11-36/checkpoint-3672/special_tokens_map.json\n",
            "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_60247332_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_21-11-36/checkpoint-3672/tokenizer_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'loss': 1.0896, 'learning_rate': 1.5104688589428795e-05, 'epoch': 3.13}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m Didn't find file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_6861ba34_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=3,per_device_trai_2022-07-21_21-11-51/checkpoint-3672/added_tokens.json. We won't load it.\n",
            "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_6861ba34_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=3,per_device_trai_2022-07-21_21-11-51/checkpoint-3672/vocab.json\n",
            "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_6861ba34_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=3,per_device_trai_2022-07-21_21-11-51/checkpoint-3672/merges.txt\n",
            "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_6861ba34_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=3,per_device_trai_2022-07-21_21-11-51/checkpoint-3672/tokenizer.json\n",
            "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m loading file None\n",
            "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_6861ba34_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=3,per_device_trai_2022-07-21_21-11-51/checkpoint-3672/special_tokens_map.json\n",
            "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_6861ba34_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=3,per_device_trai_2022-07-21_21-11-51/checkpoint-3672/tokenizer_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.2195, 'learning_rate': 1.2404892966371977e-05, 'epoch': 3.0}\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'loss': 1.0907, 'learning_rate': 1.2732721160184323e-05, 'epoch': 3.27}\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.1252, 'learning_rate': 1.0719445552462741e-05, 'epoch': 3.27}\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'loss': 1.0926, 'learning_rate': 1.0360753730939852e-05, 'epoch': 3.41}\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.1093, 'learning_rate': 9.033998138553504e-06, 'epoch': 3.54}\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'loss': 1.0908, 'learning_rate': 7.988786301695379e-06, 'epoch': 3.54}\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.1166, 'learning_rate': 7.348550724644269e-06, 'epoch': 3.81}\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'loss': 1.0899, 'learning_rate': 5.616818872450909e-06, 'epoch': 3.68}\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'loss': 1.0923, 'learning_rate': 3.244851443206437e-06, 'epoch': 3.81}\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'eval_loss': 0.7831101417541504, 'eval_automl_metric': 0.13462717058222673, 'eval_runtime': 37.9679, 'eval_samples_per_second': 128.925, 'eval_steps_per_second': 128.925, 'epoch': 4.0}\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'loss': 1.0862, 'learning_rate': 8.728840139619655e-07, 'epoch': 3.95}\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.1164, 'learning_rate': 5.663103310735033e-06, 'epoch': 4.08}\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'eval_loss': 1.0893481969833374, 'eval_automl_metric': 0.6024514811031665, 'eval_runtime': 36.2865, 'eval_samples_per_second': 134.899, 'eval_steps_per_second': 134.899, 'epoch': 4.0}\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'train_runtime': 1069.9104, 'train_samples_per_second': 54.898, 'train_steps_per_second': 13.725, 'train_loss': 1.0960205283875493, 'epoch': 4.0}\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m ***** Running Prediction *****\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m   Num examples = 4895\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m   Batch size = 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.0542, 'learning_rate': 3.977655896825797e-06, 'epoch': 4.36}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m Didn't find file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_ebe7d3ee_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=4,per_device_train_2022-07-21_21-08-22/checkpoint-11013/added_tokens.json. We won't load it.\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_ebe7d3ee_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=4,per_device_train_2022-07-21_21-08-22/checkpoint-11013/vocab.json\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_ebe7d3ee_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=4,per_device_train_2022-07-21_21-08-22/checkpoint-11013/merges.txt\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_ebe7d3ee_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=4,per_device_train_2022-07-21_21-08-22/checkpoint-11013/tokenizer.json\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m loading file None\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_ebe7d3ee_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=4,per_device_train_2022-07-21_21-08-22/checkpoint-11013/special_tokens_map.json\n",
            "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_ebe7d3ee_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=4,per_device_train_2022-07-21_21-08-22/checkpoint-11013/tokenizer_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.0618, 'learning_rate': 2.2922084829165607e-06, 'epoch': 4.63}\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.0494, 'learning_rate': 6.06761069007325e-07, 'epoch': 4.9}\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'eval_loss': 0.88468998670578, 'eval_automl_metric': 0.12972420837589382, 'eval_runtime': 37.9519, 'eval_samples_per_second': 128.979, 'eval_steps_per_second': 128.979, 'epoch': 5.0}\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'train_runtime': 873.0679, 'train_samples_per_second': 84.094, 'train_steps_per_second': 10.515, 'train_loss': 0.27977710040306475, 'epoch': 5.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m ***** Running Prediction *****\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m   Num examples = 4895\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m   Batch size = 1\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m Didn't find file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_bd71ed64_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-21_21-14-13/checkpoint-9180/added_tokens.json. We won't load it.\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_bd71ed64_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-21_21-14-13/checkpoint-9180/vocab.json\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_bd71ed64_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-21_21-14-13/checkpoint-9180/merges.txt\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_bd71ed64_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-21_21-14-13/checkpoint-9180/tokenizer.json\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m loading file None\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_bd71ed64_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-21_21-14-13/checkpoint-9180/special_tokens_map.json\n",
            "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_bd71ed64_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-21_21-14-13/checkpoint-9180/tokenizer_config.json\n",
            "2022-07-21 21:29:43,228\tINFO tune.py:747 -- Total run time: 2317.81 seconds (1801.93 seconds for the tuning loop).\n",
            "[flaml.automl: 07-21 21:29:46] {3314} INFO - selected model: None\n",
            "/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5742, 'learning_rate': 3.264882684494973e-05, 'epoch': 1.09}\n"
          ]
        }
      ],
      "source": [
        "automl_settings[\"fit_kwargs_by_estimator\"][\"transformer\"][\"model_path\"] = \"roberta-base\"\n",
        "automl_settings[\"log_file_name\"] = \"spooky_roberta.log\"\n",
        "automl_model.fit(X_train=X_train, y_train=y_train,X_val=X_val, y_val=y_val, **automl_settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHqpFgG3TjhJ",
        "outputId": "7574c558-b63e-44e1-c809-e0785a2d1dca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n",
            "8\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from flaml.data import get_output_from_log\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "for each_file_name in ['bert', 'roberta']:\n",
        "    time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
        "        get_output_from_log(filename='spooky_' + each_file_name + '.log', time_budget=3000)\n",
        "    print(len(valid_loss_history))\n",
        "    plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
        "    plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
        "\n",
        "plt.legend(['bert', 'roberta'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT7IwNCoTjhJ"
      },
      "source": [
        "## 4. Other Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzkr77iATjhJ"
      },
      "source": [
        "Besides sequence classification, FLAML currently also supports four other tasks (more tasks are to be supported, which can be found on FLAML's documentation website https://microsoft.github.io/FLAML/docs/Examples/AutoML-NLP):\n",
        "\n",
        "- sequence regression: predicting a float number from the input sequence, e.g., predicting the rating of a hotel review based on the text content;\n",
        "- token classification: predicting the label of each token in a sequence, e.g., named entity recognition;\n",
        "- multiple choice: predicting the best second half of a sentence that comes next to the first part of a sentence based on common sensen reasoning. An example is seen below;\n",
        "- (abstractive) summarization: generating the textual summarization of an input paragraph;\n",
        "\n",
        "For each task, you only have to change the \"Load data and preprocess\" with the corresponding data loading process. For example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4VgUR5TTjhJ"
      },
      "source": [
        "### 4.1 Multiple Choice Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO8GqaH3TjhJ"
      },
      "source": [
        "Multiple choice is a task of predicting the best second half of a sentence that follows the first half based on common sense reasoning. An example of multiple-choice classification problem is:\n",
        "\n",
        "On stage, a woman takes a seat at the piano. She\n",
        "a) sits on a bench as her sister plays with the doll.\n",
        "b) smiles with someone as the music plays.\n",
        "c) is in the crowd, watching the dancers.\n",
        "d) *nervously sets her fingers on the keys*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQ5fX0N3TjhJ",
        "outputId": "25e4989f-5a0e-4a85-9fea-c2d333b22e14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No config specified, defaulting to: swag/regular\n",
            "Reusing dataset swag (/home/xliu127/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c)\n",
            "No config specified, defaulting to: swag/regular\n",
            "Reusing dataset swag (/home/xliu127/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c)\n",
            "No config specified, defaulting to: swag/regular\n",
            "Reusing dataset swag (/home/xliu127/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c)\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_dataset = load_dataset(\"swag\", split=\"train\").to_pandas().iloc[:10000]\n",
        "dev_dataset = load_dataset(\"swag\", split=\"validation\").to_pandas().iloc[:10000]\n",
        "test_dataset = load_dataset(\"swag\", split=\"test\").to_pandas()\n",
        "\n",
        "custom_sent_keys = [\n",
        "        \"sent1\",\n",
        "        \"sent2\",\n",
        "        \"ending0\",\n",
        "        \"ending1\",\n",
        "        \"ending2\",\n",
        "        \"ending3\",\n",
        "        \"gold-source\",\n",
        "        \"video-id\",\n",
        "        \"startphrase\",\n",
        "        \"fold-ind\",\n",
        "    ]                                                  # specify the column names of the input sentences\n",
        "label_key = \"label\"                                    # specify the column name of the label\n",
        "\n",
        "X_train, y_train = train_dataset[custom_sent_keys], train_dataset[label_key]\n",
        "X_val, y_val = dev_dataset[custom_sent_keys], dev_dataset[label_key]\n",
        "X_test = test_dataset[custom_sent_keys]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19m2ZpRGTjhJ",
        "outputId": "7828b215-f174-4928-b0d3-00f8076946f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Members of the procession walk down the street holding small horn brass instruments.'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset.iloc[0][\"sent1\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvNeyzFsTjhJ",
        "outputId": "fc262c7a-9b50-4608-8b83-b53c2aa88f93"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-03-19 14:39:29 (running for 00:08:29.94)<br>Memory usage on this node: 33.0/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/96 CPUs, 0/4 GPUs, 0.0/250.17 GiB heap, 0.0/111.21 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: de45e672 with val_loss=0.18300000000000005 and parameters={'learning_rate': 6.104513714676502e-06, 'num_train_epochs': 2.3743291981165893, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.23610846764298543, 'weight_decay': 0.20205904544254147, 'adam_epsilon': 5.752964074991208e-08, 'seed': 41, 'global_max_steps': 9223372036854775807, 'learner': 'transformer'}<br>Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-03-19_14-30-59<br>Number of trials: 10/1000000 (10 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86157)\u001b[0m {'eval_loss': 0.6315866112709045, 'eval_automl_metric': 0.18779999999999997, 'eval_runtime': 15.4883, 'eval_samples_per_second': 645.648, 'eval_steps_per_second': 40.353, 'epoch': 1.66}\n",
            "\u001b[2m\u001b[36m(train pid=86157)\u001b[0m {'train_runtime': 190.7625, 'train_samples_per_second': 87.254, 'train_steps_per_second': 10.909, 'train_loss': 0.5091343906738046, 'epoch': 1.66}\n",
            "\u001b[2m\u001b[36m(train pid=86249)\u001b[0m {'eval_loss': 1.2118068933486938, 'eval_automl_metric': 0.2015, 'eval_runtime': 15.2585, 'eval_samples_per_second': 655.374, 'eval_steps_per_second': 40.961, 'epoch': 2.87}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86157)\u001b[0m Using amp half precision backend\n",
            "\u001b[2m\u001b[36m(train pid=86157)\u001b[0m The following columns in the test set  don't have a corresponding argument in `RobertaForMultipleChoice.forward` and have been ignored: ending3, ending1, video-id, sent1, ending0, sent2, fold-ind, ending2, startphrase, gold-source. If ending3, ending1, video-id, sent1, ending0, sent2, fold-ind, ending2, startphrase, gold-source are not expected by `RobertaForMultipleChoice.forward`,  you can safely ignore this message.\n",
            "\u001b[2m\u001b[36m(train pid=86157)\u001b[0m ***** Running Prediction *****\n",
            "\u001b[2m\u001b[36m(train pid=86157)\u001b[0m   Num examples = 10000\n",
            "\u001b[2m\u001b[36m(train pid=86157)\u001b[0m   Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86249)\u001b[0m {'eval_loss': 1.2118068933486938, 'eval_automl_metric': 0.2015, 'eval_runtime': 15.1369, 'eval_samples_per_second': 660.639, 'eval_steps_per_second': 41.29, 'epoch': 2.87}\n",
            "\u001b[2m\u001b[36m(train pid=86249)\u001b[0m {'train_runtime': 546.3809, 'train_samples_per_second': 156.658, 'train_steps_per_second': 39.165, 'train_loss': 0.5030154804349909, 'epoch': 2.87}\n",
            "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m {'loss': 0.4854, 'learning_rate': 1.3592147782116173e-06, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86249)\u001b[0m Using amp half precision backend\n",
            "\u001b[2m\u001b[36m(train pid=86249)\u001b[0m The following columns in the test set  don't have a corresponding argument in `RobertaForMultipleChoice.forward` and have been ignored: fold-ind, sent2, gold-source, ending1, startphrase, sent1, ending0, video-id, ending2, ending3. If fold-ind, sent2, gold-source, ending1, startphrase, sent1, ending0, video-id, ending2, ending3 are not expected by `RobertaForMultipleChoice.forward`,  you can safely ignore this message.\n",
            "\u001b[2m\u001b[36m(train pid=86249)\u001b[0m ***** Running Prediction *****\n",
            "\u001b[2m\u001b[36m(train pid=86249)\u001b[0m   Num examples = 10000\n",
            "\u001b[2m\u001b[36m(train pid=86249)\u001b[0m   Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m {'eval_loss': 0.49709731340408325, 'eval_automl_metric': 0.17600000000000005, 'eval_runtime': 15.4983, 'eval_samples_per_second': 645.232, 'eval_steps_per_second': 40.327, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-19 14:41:56,719\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m {'eval_loss': 0.5254333019256592, 'eval_automl_metric': 0.17800000000000005, 'eval_runtime': 15.45, 'eval_samples_per_second': 647.251, 'eval_steps_per_second': 40.453, 'epoch': 3.0}\n",
            "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m {'loss': 0.3989, 'learning_rate': 3.8051750127352887e-07, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-19 14:42:56,729\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m {'eval_loss': 0.5254867076873779, 'eval_automl_metric': 0.17789999999999995, 'eval_runtime': 15.424, 'eval_samples_per_second': 648.341, 'eval_steps_per_second': 40.521, 'epoch': 3.0}\n",
            "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m {'eval_loss': 0.5332269072532654, 'eval_automl_metric': 0.17830000000000001, 'eval_runtime': 15.4452, 'eval_samples_per_second': 647.45, 'eval_steps_per_second': 40.466, 'epoch': 3.39}\n",
            "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m {'train_runtime': 382.2827, 'train_samples_per_second': 88.597, 'train_steps_per_second': 11.076, 'train_loss': 0.5299136270370808, 'epoch': 3.39}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-19 14:43:56,739\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n",
            "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m Using amp half precision backend\n",
            "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m The following columns in the test set  don't have a corresponding argument in `RobertaForMultipleChoice.forward` and have been ignored: ending2, sent1, ending0, sent2, ending3, video-id, gold-source, ending1, startphrase, fold-ind. If ending2, sent1, ending0, sent2, ending3, video-id, gold-source, ending1, startphrase, fold-ind are not expected by `RobertaForMultipleChoice.forward`,  you can safely ignore this message.\n",
            "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m ***** Running Prediction *****\n",
            "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m   Num examples = 10000\n",
            "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m   Batch size = 16\n",
            "2022-03-19 14:44:14,271\tINFO tune.py:639 -- Total run time: 795.18 seconds (504.18 seconds for the tuning loop).\n",
            "[flaml.automl: 03-19 14:44:19] {2837} INFO - selected model: None\n",
            "/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6603, 'learning_rate': 4.631567529441369e-06, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[flaml.automl: 03-19 14:46:08] {2947} INFO - retrain transformer for 109.2s\n",
            "[flaml.automl: 03-19 14:46:08] {2954} INFO - retrained model: None\n",
            "[flaml.automl: 03-19 14:46:08] {2283} INFO - fit succeeded\n",
            "[flaml.automl: 03-19 14:46:08] {2284} INFO - Time taken to find the best model: 319.927033662796\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 96.899, 'train_samples_per_second': 245.031, 'train_steps_per_second': 30.63, 'train_loss': 0.6602518278346073, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "''' import AutoML class from flaml package '''\n",
        "from flaml import AutoML\n",
        "automl = AutoML()\n",
        "\n",
        "if not ray.is_initialized():\n",
        "    ray.init()\n",
        "\n",
        "automl_settings = {\n",
        "    \"time_budget\": 500,                 # setting the time budget\n",
        "    \"task\": \"multichoice-classification\",       # setting the task as multiplechoice-classification\n",
        "    \"fit_kwargs_by_estimator\": {          # if model_path is not set, the default model is facebook/muppet-roberta-base: https://huggingface.co/facebook/muppet-roberta-base\n",
        "        \"transformer\": {\n",
        "            \"output_dir\": \"data/output/\",  # setting the output directory\n",
        "            \"per_device_eval_batch_size\": 16, # the batch size for validation (inference)\n",
        "        }\n",
        "    },\n",
        "    \"gpu_per_trial\": 1,                 # set to 0 if no GPU is available\n",
        "    \"log_file_name\": \"seqclass.log\",    # set the file to save the log for HPO\n",
        "    \"log_type\": \"all\",                  # the log type for trials: \"all\" if logging all the trials, \"better\" if only keeping the better trials\n",
        "    \"use_ray\": {\"local_dir\": \"data/output/\"},                    # set whether to use Ray\n",
        "    \"n_concurrent_trials\": 4\n",
        "}\n",
        "\n",
        "'''The main flaml automl API'''\n",
        "automl.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **automl_settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kh7ZJsIKTjhJ",
        "outputId": "9b96820c-a889-48f0-d697-6c7f5ea931f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 0.00021956991427751982, 'num_train_epochs': 0.3549576494055084, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.07425273520338253, 'weight_decay': 0.03879221030529465, 'adam_epsilon': 3.7880482987985576e-08, 'seed': 43, 'global_max_steps': 444, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 0.00021956991427751982, 'num_train_epochs': 0.3549576494055084, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.07425273520338253, 'weight_decay': 0.03879221030529465, 'adam_epsilon': 3.7880482987985576e-08, 'seed': 43, 'global_max_steps': 444, 'learner': 'transformer'}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.3241899893349513e-06, 'num_train_epochs': 0.4379128434860086, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.257055208282222, 'weight_decay': 0.012652183020312091, 'adam_epsilon': 1.0189125195705357e-07, 'seed': 43, 'global_max_steps': 274, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 0.0002562922748967212, 'num_train_epochs': 0.1802995999606059, 'per_device_train_batch_size': 4, 'warmup_ratio': 0.1809477882684876, 'weight_decay': 0.10305626005953175, 'adam_epsilon': 5.536776887412208e-08, 'seed': 42, 'global_max_steps': 451, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 6.104513714676502e-06, 'num_train_epochs': 2.3743291981165893, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.23610846764298543, 'weight_decay': 0.20205904544254147, 'adam_epsilon': 5.752964074991208e-08, 'seed': 41, 'global_max_steps': 1251, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 6.104513714676502e-06, 'num_train_epochs': 2.3743291981165893, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.23610846764298543, 'weight_decay': 0.20205904544254147, 'adam_epsilon': 5.752964074991208e-08, 'seed': 41, 'global_max_steps': 1251, 'learner': 'transformer'}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 9.306519250357542e-06, 'num_train_epochs': 0.4664878701006166, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 5.931759315303309e-07, 'seed': 43, 'global_max_steps': 147, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 6.104513714676502e-06, 'num_train_epochs': 2.3743291981165893, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.23610846764298543, 'weight_decay': 0.20205904544254147, 'adam_epsilon': 5.752964074991208e-08, 'seed': 41, 'global_max_steps': 1251, 'learner': 'transformer'}}\n",
            "6\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from flaml.data import get_output_from_log\n",
        "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
        "    get_output_from_log(filename=automl_settings['log_file_name'], time_budget=3000)\n",
        "for config in config_history:\n",
        "    print(config)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Wall Clock Time (s)')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "print(len(valid_loss_history))\n",
        "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
        "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "664qCdihTjhJ"
      },
      "source": [
        "### 4.2 Text Summarization Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmB4kaF_TjhJ"
      },
      "source": [
        "The text summarization task summarizes a long text into a short sentence. For example:\n",
        "\n",
        "- Document: Army explosives experts were called out to deal with a suspect package at the offices on the Newtownards Road on Friday night. Roads were sealed off and traffic diverted as a controlled explosion was carried out. The premises, used by East Belfast MP Naomi Long, have been targeted a number of times. Most recently, petrol bomb attacks were carried out on the offices on consecutive nights in April and May. The attacks began following a Belfast City Council vote in December 2012 restricting the flying of the union flag at the City Hall. Condemning the latest hoax, Alliance MLA Chris Lyttle said: \"It is a serious incident for the local area, it causes serious disruption, it puts people's lives at risk, it can prevent emergency services reaching the area. \"Ultimately we need people with information to share that with the police in order for them to do their job and bring these people to justice.\n",
        "\n",
        "- Summary: A suspicious package left outside an Alliance Party office in east Belfast has been declared a hoax.\n",
        "\n",
        "In this example, we use FLAML to perform *abstractive summarization* using the t5-small language model, i.e., the summary is generated word-by-word. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amlQnvcxTjhK",
        "outputId": "078c91e6-ed98-4774-85b4-f9a14b280f0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset xsum (/home/xliu127/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "204045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset xsum (/home/xliu127/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n",
            "Using custom data configuration default\n",
            "Reusing dataset xsum (/home/xliu127/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_dataset = load_dataset(\"xsum\", split=\"train\").to_pandas()\n",
        "print(len(train_dataset))\n",
        "dev_dataset = load_dataset(\"xsum\", split=\"validation\").to_pandas()\n",
        "test_dataset = load_dataset(\"xsum\", split=\"test\").to_pandas()\n",
        "\n",
        "custom_sent_keys = [\"document\"]       # specify the column names of the input sentences\n",
        "label_key = \"summary\"                 # specify the column name of the label                              \n",
        "\n",
        "X_train, y_train = train_dataset[custom_sent_keys], train_dataset[label_key]\n",
        "X_val, y_val = dev_dataset[custom_sent_keys], dev_dataset[label_key]\n",
        "X_test = test_dataset[custom_sent_keys]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYq8XAtxTjhK",
        "outputId": "172a5c63-60dc-4507-9c66-40ea0fde196c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-03-19 14:55:00 (running for 00:08:31.38)<br>Memory usage on this node: 23.1/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/96 CPUs, 0/4 GPUs, 0.0/250.17 GiB heap, 0.0/111.21 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: 08b6571c with val_loss=0.8569452656271894 and parameters={'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 9223372036854775807, 'learner': 'transformer', 'FLAML_sample_size': 10000}<br>Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-03-19_14-46-29<br>Number of trials: 8/1000000 (8 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m   warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m {'loss': 8.7635, 'learning_rate': 1.2308416834153697e-05, 'epoch': 0.11}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m   warnings.warn(\n",
            "2022-03-19 14:56:00,679\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n",
            "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m [nltk_data] Downloading package punkt to /home/xliu127/nltk_data...\n",
            "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m [nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m {'eval_loss': 6.893245697021484, 'eval_automl_metric': 0.8537338408275918, 'eval_runtime': 102.2734, 'eval_samples_per_second': 110.801, 'eval_steps_per_second': 6.932, 'epoch': 0.11}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-19 14:57:00,687\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n",
            "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m [nltk_data] Downloading package punkt to /home/xliu127/nltk_data...\n",
            "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m [nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m {'eval_loss': 7.381210803985596, 'eval_automl_metric': 0.8475751825208984, 'eval_runtime': 107.4032, 'eval_samples_per_second': 105.509, 'eval_steps_per_second': 6.601, 'epoch': 0.16}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m [nltk_data] Downloading package punkt to /home/xliu127/nltk_data...\n",
            "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m [nltk_data]   Package punkt is already up-to-date!\n",
            "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m [nltk_data] Downloading package punkt to /home/xliu127/nltk_data...\n",
            "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m [nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m {'eval_loss': 10.150897979736328, 'eval_automl_metric': 0.8566791839938478, 'eval_runtime': 108.2143, 'eval_samples_per_second': 104.718, 'eval_steps_per_second': 6.552, 'epoch': 0.36}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-19 14:58:00,697\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m {'eval_loss': 11.665904998779297, 'eval_automl_metric': 0.858011676038827, 'eval_runtime': 109.4667, 'eval_samples_per_second': 103.52, 'eval_steps_per_second': 6.477, 'epoch': 0.38}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m [nltk_data] Downloading package punkt to /home/xliu127/nltk_data...\n",
            "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m [nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m {'eval_loss': 6.893245697021484, 'eval_automl_metric': 0.8537338408275918, 'eval_runtime': 110.7246, 'eval_samples_per_second': 102.344, 'eval_steps_per_second': 6.403, 'epoch': 0.11}\n",
            "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m {'train_runtime': 220.8946, 'train_samples_per_second': 4.648, 'train_steps_per_second': 0.149, 'train_loss': 8.763471198804451, 'epoch': 0.11}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-19 14:59:00,706\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n",
            "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m Using amp half precision backend\n",
            "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m ***** Running Prediction *****\n",
            "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m   Num examples = 11332\n",
            "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m   Batch size = 16\n",
            "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m [nltk_data] Downloading package punkt to /home/xliu127/nltk_data...\n",
            "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m [nltk_data]   Package punkt is already up-to-date!\n",
            "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m [nltk_data] Downloading package punkt to /home/xliu127/nltk_data...\n",
            "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m [nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m {'eval_loss': 7.381210803985596, 'eval_automl_metric': 0.8475751825208984, 'eval_runtime': 109.1975, 'eval_samples_per_second': 103.775, 'eval_steps_per_second': 6.493, 'epoch': 0.16}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m [nltk_data] Downloading package punkt to /home/xliu127/nltk_data...\n",
            "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m [nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m {'train_runtime': 232.9303, 'train_samples_per_second': 10.067, 'train_steps_per_second': 1.262, 'train_loss': 9.880440506280637, 'epoch': 0.16}\n",
            "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m {'eval_loss': 10.150897979736328, 'eval_automl_metric': 0.8566791839938478, 'eval_runtime': 108.3182, 'eval_samples_per_second': 104.618, 'eval_steps_per_second': 6.546, 'epoch': 0.36}\n",
            "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m {'train_runtime': 232.4568, 'train_samples_per_second': 92.218, 'train_steps_per_second': 2.887, 'train_loss': 11.215172903878349, 'epoch': 0.36}\n",
            "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m {'eval_loss': 11.665904998779297, 'eval_automl_metric': 0.858011676038827, 'eval_runtime': 110.526, 'eval_samples_per_second': 102.528, 'eval_steps_per_second': 6.415, 'epoch': 0.38}\n",
            "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m {'train_runtime': 236.6253, 'train_samples_per_second': 19.714, 'train_steps_per_second': 0.621, 'train_loss': 11.549961930614407, 'epoch': 0.38}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-19 15:00:00,942\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n",
            "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m Using amp half precision backend\n",
            "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m ***** Running Prediction *****\n",
            "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m   Num examples = 11332\n",
            "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m   Batch size = 16\n",
            "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m Using amp half precision backend\n",
            "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m ***** Running Prediction *****\n",
            "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m   Num examples = 11332\n",
            "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m   Batch size = 16\n",
            "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m Using amp half precision backend\n",
            "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m ***** Running Prediction *****\n",
            "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m   Num examples = 11332\n",
            "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m   Batch size = 16\n",
            "2022-03-19 15:01:00,948\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n",
            "2022-03-19 15:02:20,150\tINFO tune.py:639 -- Total run time: 950.87 seconds (500.36 seconds for the tuning loop).\n",
            "[flaml.automl: 03-19 15:02:25] {2837} INFO - selected model: None\n",
            "/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "[flaml.automl: 03-19 15:14:54] {2947} INFO - retrain transformer for 748.2s\n",
            "[flaml.automl: 03-19 15:14:54] {2954} INFO - retrained model: None\n",
            "[flaml.automl: 03-19 15:14:54] {2283} INFO - fit succeeded\n",
            "[flaml.automl: 03-19 15:14:54] {2284} INFO - Time taken to find the best model: 472.3055913448334\n",
            "[flaml.automl: 03-19 15:14:54] {2295} WARNING - Time taken to find the best model is 94% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 14.6848, 'train_samples_per_second': 13894.959, 'train_steps_per_second': 434.258, 'train_loss': 10.199760437011719, 'epoch': 0.02}\n"
          ]
        }
      ],
      "source": [
        "''' import AutoML class from flaml package '''\n",
        "from flaml import AutoML\n",
        "automl = AutoML()\n",
        "\n",
        "import ray\n",
        "if not ray.is_initialized():\n",
        "    ray.init()\n",
        "\n",
        "automl_settings = {\n",
        "    \"time_budget\": 500,         # setting the time budget\n",
        "    \"task\": \"summarization\",    # setting the task as summarization\n",
        "    \"fit_kwargs_by_estimator\": {  # if model_path is not set, the default model is t5-small: https://huggingface.co/t5-small\n",
        "        \"transformer\": {\n",
        "            \"output_dir\": \"data/output/\",  # setting the output directory\n",
        "            \"model_path\": \"t5-small\",\n",
        "            \"per_device_eval_batch_size\": 16,  # the batch size for validation (inference)\n",
        "        }\n",
        "    },\n",
        "    \"gpu_per_trial\": 1,  # set to 0 if no GPU is available\n",
        "    \"log_file_name\": \"seqclass.log\",  # set the file to save the log for HPO\n",
        "    \"log_type\": \"all\",   # the log type for trials: \"all\" if logging all the trials, \"better\" if only keeping the better trials\n",
        "    \"use_ray\": {\"local_dir\": \"data/output/\"},  # set whether to use Ray\n",
        "    \"metric\": \"rouge1\",\n",
        "    \"n_concurrent_trials\": 4,  # sample: False # if the time is sufficient (e.g., longer than one trial's running time), you can set \n",
        "}\n",
        "\n",
        "'''The main flaml automl API'''\n",
        "automl.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **automl_settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPy67MBFTjhK",
        "outputId": "fe0ca67e-b129-4889-ee03-972620bc8421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 3.6439277745413994e-06, 'num_train_epochs': 0.454119690781029, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.04654549348562217, 'weight_decay': 0.06669806327326033, 'adam_epsilon': 2.5833461668835812e-08, 'seed': 42, 'global_max_steps': 125, 'learner': 'transformer', 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.6439277745413994e-06, 'num_train_epochs': 0.454119690781029, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.04654549348562217, 'weight_decay': 0.06669806327326033, 'adam_epsilon': 2.5833461668835812e-08, 'seed': 42, 'global_max_steps': 125, 'learner': 'transformer', 'FLAML_sample_size': 10000}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 112, 'learner': 'transformer', 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 112, 'learner': 'transformer', 'FLAML_sample_size': 10000}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 3.4236378229097798e-06, 'num_train_epochs': 8.919336644807531, 'per_device_train_batch_size': 4, 'warmup_ratio': 0.022492820063166875, 'weight_decay': 0.27013721375576616, 'adam_epsilon': 6.366959214432801e-08, 'seed': 43, 'global_max_steps': 180, 'learner': 'transformer', 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 112, 'learner': 'transformer', 'FLAML_sample_size': 10000}}\n",
            "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 2.83823390666728e-06, 'num_train_epochs': 1.6667827812145841, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.04013366246992448, 'weight_decay': 0.2945152447208819, 'adam_epsilon': 4.694476379503266e-08, 'seed': 43, 'global_max_steps': 163, 'learner': 'transformer', 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 112, 'learner': 'transformer', 'FLAML_sample_size': 10000}}\n",
            "4\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "from flaml.data import get_output_from_log\n",
        "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
        "    get_output_from_log(filename=automl_settings['log_file_name'], time_budget=3000)\n",
        "for config in config_history:\n",
        "    print(config)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Wall Clock Time (s)')\n",
        "plt.ylabel('Rouge 1')\n",
        "print(len(valid_loss_history))\n",
        "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
        "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "e9d36fc5b7c3dd4177ff1b60184dd696c0acc18150a44682abca4d769811bd46"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "name": "automl_nlp.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}