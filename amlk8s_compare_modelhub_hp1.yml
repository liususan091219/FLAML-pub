description: finetuning test on AMLK8s

target:
  service: amlk8s
  name: ms-shared

environment:
  image: sonichi/hpo4hf:latest
  setup:
    # - pip install transformers datasets wandb prompt_toolkit==1.0.14 --user
    # - sudo apt-get -y install git
    - git clone https://github.com/liususan091219/FLAML.git
    - cd FLAML
    - git checkout exp
    - pip install -e.[blendsearch,ray] --user
    - pip install 'tensorboardX<=2.2' azure-storage-blob --user
    - export MKL_NUM_THREADS=1

code:
  local_dir: $CONFIG_DIR/key/

search:
  job_template:
    name: _{experiment_name:s}_{auto:3s}
    sku: G1-V100 ^itpwus2v100cl-s,itp-v100-scus-2,itp-v100-eus,itpeastusv100cl,ms-eus-v100-webx,itp-v100-wus2,sea-v100-16-ms,itpscusv100cl,itphyperdgxcl1-s,itpeastusv100cl2,itphyperdgx2cl1,ms-weu-v100-webx,ccp-v100,g-v100-4x-weu,itpmtlv100cl1-s,g-v100-8x-ncus,ms-aip-webxt,v100-scus,ms-scus-v1002-we,g-v100-8x-eus-1
    command:
    - python FLAML/test/hf/run_autohf.py --dataset_subdataset_name {dataset_subdataset_name} --pretrained_model_size {pretrained_model_size} --key_path "." --sample_num 1 --time_budget 10000 --root_log_path "logs_modelhub/hp1/" --resplit_mode rspt --space_mode uni --search_alg_args_mode cus --algo_mode hpo
    submit_args: &retry_args
      max_attempts: 0
  type: grid
  max_trials: 59
  params:
    - name: pretrained_model_size
      spec: discrete
      values: ["prajjwal1/bert-tiny small",
               "mrm8488/bert-tiny-finetuned-sms-spam-detection small",
               "microsoft/deberta-base small",
               "shahrukhx01/question-vs-statement-classifier small",
               "albert-base-v2 small",
               "albert-base-v1 small",
               "cointegrated/rubert-tiny small",
               "microsoft/xtremedistil-l6-h256-uncased small",
               "google/electra-small-generator small",
               "google/electra-small-discriminator small",
               "albert-large-v2 small",
               "albert-large-v1 small",
               "microsoft/xtremedistil-l6-h384-uncased small",
               "mrm8488/chEMBL26_smiles_v2 small",
               "microsoft/xtremedistil-l12-h384-uncased base",
               "google/electra-base-generator base",
               "google/electra-large-generator base",
               "albert-xlarge-v2 base",
               "albert-xlarge-v1 base",
               "distilbert-base-uncased base",
               "mrm8488/distilroberta-finetuned-tweets-hate-speech base",
               "distilroberta-base base",
               "bert-base-uncased base",
               "bert-base-cased base",
               "emilyalsentzer/Bio_ClinicalBERT base",
               "emilyalsentzer/Bio_Discharge_Summary_BERT base",
               "Intel/bert-base-uncased-sparse-70-unstructured base",
               "Intel/bert-base-uncased-mnli-sparse-70-unstructured-no-classifier base",
               "severo/autonlp-sentiment_detection-1781580 base",
               "nlpaueb/legal-bert-base-uncased base",
               "google/electra-base-discriminator base",
               "zlucia/legalbert base",
               "zlucia/custom-legalbert base",
               "lordtt13/COVID-SciBERT base",
               "saibo/legal-roberta-base base",
               "mrm8488/codebert-base-finetuned-detect-insecure-code base",
               "aychang/roberta-base-imdb base",
               "EMBEDDIA/crosloengual-bert base",
               "facebook/muppet-roberta-base base",
               "VictorSanh/roberta-base-finetuned-yelp-polarity base",
               "roberta-base base",
               "microsoft/deberta-base-mnli base",
               "microsoft/deberta-base base",
               "EMBEDDIA/finest-bert base",
               "bert-base-multilingual-uncased base",
               "sagorsarker/codeswitch-spaeng-sentiment-analysis-lince base",
               "albert-xxlarge-v2 large",
               "albert-xxlarge-v1 large",
               "bert-large-cased large",
               "bert-large-cased-whole-word-masking large",
               "roberta-large large",
               "bert-large-uncased large",
               "bert-large-uncased-whole-word-masking large",
               "google/bigbird-roberta-large large",
               "facebook/muppet-roberta-large large",
               "siebert/sentiment-roberta-large-english large",
               "idjotherwise/autonlp-reading_prediction-172506 large",
               "microsoft/deberta-large large",
               "microsoft/deberta-large-mnli large"
               ]
    - name: dataset_subdataset_name
      spec: discrete
      values: ["amazon_polarity:"]
      # imdb: -> glue:sst2 -> yelp_polarity: -> hate_offensive: -> dbpedia_14:
