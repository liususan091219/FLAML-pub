description: finetuning test on AMLK8s

target:
  service: amlk8s
  name: ms-shared-v100

environment:
  image: sonichi/hpo4hf:latest
  setup:
    # - pip install transformers datasets wandb prompt_toolkit==1.0.14 --user
    # - sudo apt-get -y install git
    - git clone https://github.com/liususan091219/FLAML.git
    - cd FLAML
    - git checkout exp
    - pip install -e.[blendsearch,ray] --user
    - export WANDB_API_KEY=7553d982a2247ca8324ec648bd302678105e1058
    - pip install azure-storage-blob

code:
  local_dir: $CONFIG_DIR/../key/

search:
  job_template:
    name: ms-shared
    sku: G4-V100
    command:
    - python FLAML/test/hf/run_autohf.py --server_name tmdev --algo_mode {algo_mode} --dataset_subdataset_name {dataset_subdataset_name} --space_mode {space_mode} --algo_name {algo_name} --pruner {pruner} --pretrained_model_size {pretrained_model} --data_root_dir 'data/' --sample_num 10000 --time_budget 14400 --rep_id {rep_id} --resplit_mode {resplit_mode} --search_alg_args_mode {search_alg_args_mode} --key_path . --root_log_path {root_log_path}
    submit_args: &retry_args
      max_attempts: 0
  type: grid
  max_trials: 27
  params:
    - name: algo_mode
      spec: discrete
      values: ["hpo"]
    - name: algo_name
      spec: discrete
      values: ["bs","cfo","optuna"]
    - name: resplit_mode
      spec: discrete
      values: ["rspt"]
    - name: pruner
      spec: discrete
      values: ["None"]
    - name: space_mode
      spec: discrete
      values: ["uni"]
    - name: pretrained_model
      spec: discrete
      values: ["funnel-transformer/xlarge-base:xlarge"]
    - name: dataset_subdataset_name
      spec: discrete
      values: ["glue:cola", "glue:mrpc", "glue:rte"]
    - name: search_alg_args_mode
      spec: discrete
      values: ["dft"]
    - name: rep_id
      spec: discrete
      values: [0,1,2]
    - name: root_log_path
      spec: discrete
      values: ["logs_seed/"]